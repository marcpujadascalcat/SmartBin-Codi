{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a21a2cd5-5ffa-4371-929f-d650ae0db6b6",
   "metadata": {},
   "source": [
    "# **SmartBin:** *Versi√≥ 2.1.*\n",
    "\n",
    "> **Aquest notebook ha estat generat amb assist√®ncia d‚Äôintel¬∑lig√®ncia artificial, per√≤ totes les decisions sobre les t√®cniques i metodologies utilitzades han estat preses per una persona humana.**\n",
    "\n",
    "## üß© Descripci√≥ general\n",
    "\n",
    "Aquest notebook forma part del projecte **SmartBin**, un sistema de classificaci√≥ autom√†tica de residus mitjan√ßant **visi√≥ per computador** i **aprenentatge autom√†tic**.  \n",
    "L‚Äôobjectiu principal d‚Äôaquesta versi√≥ (2.1) √©s **optimitzar el model de classificaci√≥ desenvolupat en la versi√≥ anterior (2.0)**, millorant-ne la precisi√≥ i reduint el temps d‚Äôentrenament mitjan√ßant dues t√®cniques complement√†ries d‚Äôoptimitzaci√≥:\n",
    "\n",
    "1. **Grid Search:** una aproximaci√≥ inicial, simple i exhaustiva que prova totes les combinacions possibles dins d‚Äôun conjunt predefinit d‚Äôhiperpar√†metres.  \n",
    "2. **Optuna:** una optimitzaci√≥ adaptativa i intel¬∑ligent que apr√®n dels resultats previs i ajusta els par√†metres de manera din√†mica per trobar la millor configuraci√≥.\n",
    "\n",
    "> **Dataset utilitzat:** [Recyclable and Household Waste Classification (Kaggle)](https://www.kaggle.com/datasets/alistairking/recyclable-and-household-waste-classification)\n",
    "\n",
    "Aquest conjunt de dades cont√© imatges de diferents categories de residus reciclables i dom√®stics (com paper, pl√†stic, metall, vidre o org√†nic), organitzades en carpetes segons la seva classe.  \n",
    "Cada imatge √©s processada i redimensionada per entrenar un model de visi√≥ per computador capa√ß d‚Äôidentificar autom√†ticament el tipus de residu corresponent.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Grid Search: una aproximaci√≥ inicial\n",
    "\n",
    "El **Grid Search** √©s un m√®tode d‚Äôoptimitzaci√≥ **m√©s simple i determinista** que Optuna.  \n",
    "A difer√®ncia d‚Äôaquest √∫ltim ,que explora l‚Äôespai d‚Äôhiperpar√†metres de manera intel¬∑ligent i din√†mica, el Grid Search **prova totes les combinacions possibles dins d‚Äôun conjunt de valors preestablerts**.  \n",
    "Aix√≤ permet acotar r√†pidament els intervals on √©s probable que es trobin els millors par√†metres, per√≤ sense la complexitat ni l‚Äôefici√®ncia adaptativa d‚ÄôOptuna.\n",
    "\n",
    "En el codi, aquest proc√©s recorre totes les combinacions possibles de tres hiperpar√†metres definits manualment:\n",
    "\n",
    "- **Velocitat d‚Äôaprenentatge (`learning_rate`)**  \n",
    "- **Mida del lot (`batch_size`)**  \n",
    "- **Nombre d‚Äô√®poques (`num_epochs`)**\n",
    "\n",
    "Per a cada combinaci√≥:\n",
    "1. Es carreguen les dades d‚Äôentrenament i validaci√≥ amb transformacions d‚Äôimatge (redimensionament, conversi√≥ a tensor i normalitzaci√≥).  \n",
    "2. Es crea i entrena una **xarxa neuronal convolucional (CNN)** amb aquests valors.  \n",
    "3. Es calcula la **p√®rdua mitjana de validaci√≥ (`val_loss`)**, que mesura el rendiment del model.  \n",
    "4. Es desa el resultat per comparar-lo amb la resta de combinacions.\n",
    "\n",
    "Quan s‚Äôhan provat totes les configuracions, el codi **identifica autom√†ticament la combinaci√≥ amb la p√®rdua de validaci√≥ m√©s baixa**, considerant-la la millor opci√≥ dins del conjunt predefinit.  \n",
    "Per garantir un √∫s eficient dels recursos, despr√©s de cada prova s‚Äôallibera la mem√≤ria GPU amb `torch.cuda.empty_cache()` i `gc.collect()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8d2c00-20c4-4a94-8259-19af95c2a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import gc  # per netejar la mem√≤ria\n",
    "import time\n",
    "\n",
    "# Preprocessament\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Hiperpar√†metres a provar\n",
    "learning_rates = [0.0001, 0.0005, 0.001]\n",
    "batch_sizes = [32, 64]\n",
    "epoch_options = [5, 10]\n",
    "\n",
    "# Guardar resultats\n",
    "best_val_loss = float('inf')\n",
    "best_config = {}\n",
    "results = []\n",
    "\n",
    "# üîÅ Grid Search\n",
    "for lr in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        for num_epochs in epoch_options:\n",
    "            print(f\"\\nüîß Prova: lr={lr}, batch_size={batch_size}, epochs={num_epochs}\")\n",
    "\n",
    "            # Dataset i Dataloader\n",
    "            train_dataset = WasteDataset(\"images\", split='train', transform=transform)\n",
    "            val_dataset = WasteDataset(\"images\", split='val', transform=transform)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            # Model\n",
    "            model = CNN(num_classes=len(train_dataset.classes)).to('cuda')\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            # Entrenament\n",
    "            for epoch in range(num_epochs):\n",
    "                model.train()\n",
    "                for images, labels in train_loader:\n",
    "                    images, labels = images.to('cuda'), labels.to('cuda')\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # Validaci√≥\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to('cuda'), labels.to('cuda')\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item() * images.size(0)\n",
    "\n",
    "            val_loss /= len(val_dataset)\n",
    "            print(f\"üìâ Val loss: {val_loss:.4f}\")\n",
    "\n",
    "            results.append((lr, batch_size, num_epochs, val_loss))\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_config = {\n",
    "                    'learning_rate': lr,\n",
    "                    'batch_size': batch_size,\n",
    "                    'num_epochs': num_epochs,\n",
    "                    'val_loss': val_loss\n",
    "                }\n",
    "\n",
    "            # üßπ Alliberar mem√≤ria\n",
    "            del model\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "# üèÜ Millor combinaci√≥\n",
    "print(\"\\n‚úÖ Millor combinaci√≥ trobada:\")\n",
    "print(best_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dcbd22-27e3-44fc-ad65-c941f24ac980",
   "metadata": {},
   "source": [
    "## Optimitzaci√≥ amb Optuna\n",
    "\n",
    "Despr√©s d‚Äôhaver establert uns valors de refer√®ncia mitjan√ßant el **Grid Search**, aquesta secci√≥ aprofundeix en la **optimitzaci√≥ autom√†tica dels hiperpar√†metres** amb la llibreria **Optuna**.  \n",
    "A difer√®ncia del Grid Search ,que explora combinacions predefinides de manera exhaustiva per√≤ limitada, Optuna utilitza un **enfocament adaptatiu i intel¬∑ligent** que apr√®n dels resultats obtinguts en cada *trial* per dirigir la cerca cap a les zones m√©s prometedores de l‚Äôespai d‚Äôhiperpar√†metres.\n",
    "\n",
    "### Principi de funcionament\n",
    "\n",
    "Optuna treballa mitjan√ßant un sistema de **proves iteratives (*trials*)**, en qu√® cada trial representa un entrenament complet del model amb una combinaci√≥ diferent d‚Äôhiperpar√†metres.  \n",
    "A trav√©s del seu m√®tode de mostreig basat en el **TPE (*Tree-structured Parzen Estimator*)**, la llibreria ajusta progressivament les seves eleccions segons els resultats previs, concentrant-se en aquells valors que minimitzen la **p√®rdua de validaci√≥**.\n",
    "\n",
    "A m√©s, el proc√©s incorpora dos mecanismes essencials per millorar l‚Äôefici√®ncia:\n",
    "- **Early Stopping**: atura l‚Äôentrenament si no s‚Äôobserva millora despr√©s d‚Äôun cert nombre d‚Äô√®poques, evitant c√†lculs innecessaris.  \n",
    "- **Pruning**: interromp autom√†ticament els *trials* que no mostren resultats prometedors, permetent centrar els recursos en configuracions m√©s adequades.\n",
    "\n",
    "### Hiperpar√†metres optimitzats\n",
    "\n",
    "En aquest cas, Optuna explora un espai d‚Äôhiperpar√†metres centrat al voltant dels valors trobats amb el Grid Search:\n",
    "\n",
    "| Par√†metre | Rang o valors explorats |\n",
    "|------------|--------------------------|\n",
    "| `learning_rate` | 0.0001 ‚Äì 0.001 (escala logar√≠tmica) |\n",
    "| `batch_size` | [16, 24, 32, 48, 64] |\n",
    "| `num_epochs` | 3 ‚Äì 8 |\n",
    "| `dropout` | 0.3 ‚Äì 0.7 |\n",
    "\n",
    "Cada combinaci√≥ es prova durant un nombre d‚Äô√®poques limitat, amb una paci√®ncia m√†xima de tres iteracions sense millora per evitar sobreentrenament.\n",
    "\n",
    "### Avaluaci√≥ i selecci√≥ del millor model\n",
    "\n",
    "Durant la optimitzaci√≥, Optuna:\n",
    "1. Entrena el model amb la configuraci√≥ proposada en cada *trial*.  \n",
    "2. Calcula la **p√®rdua de validaci√≥ (`val_loss`)** com a m√®trica objectiu.  \n",
    "3. Actualitza els seus models interns per ajustar la cerca en els seg√ºents *trials*.  \n",
    "4. Desa autom√†ticament l‚Äôestat del **millor model trobat** quan s‚Äôobt√© una millora global.\n",
    "\n",
    "Quan el proc√©s finalitza (despr√©s de 15 *trials* o tres hores m√†ximes d‚Äôexecuci√≥), es recupera el **millor conjunt d‚Äôhiperpar√†metres** i s‚Äôentrena el model definitiu, que posteriorment s‚Äôavalua sobre el conjunt de **test** per verificar la seva generalitzaci√≥.\n",
    "\n",
    "### Resultats i informes generats\n",
    "\n",
    "En finalitzar la optimitzaci√≥, el notebook genera autom√†ticament:\n",
    "- **Matriu de confusi√≥ (`best_model_confusion_matrix.png`)**, que mostra els encerts i errors per classe.  \n",
    "- **Informe complet (`optimization_report.json`)** amb hiperpar√†metres, m√®triques i historial dels *trials*.  \n",
    "- **Gr√†fic d‚Äôhist√≤ria (`optimization_history.png`)**, que il¬∑lustra l‚Äôevoluci√≥ de la p√®rdua de validaci√≥ al llarg dels *trials*.  \n",
    "- **Model final optimitzat (`optimized_best_model.pth`)**, llest per a la seva reutilitzaci√≥ o integraci√≥.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5c920ec-a3cb-40cd-873d-ad6a6c4fd741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 17:18:27,903] A new study created in memory with name: no-name-460ab4f7-605c-40cc-8b92-21d76f8b5910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ INICIANDO OPTUNA HYPERPARAMETER TUNING\n",
      "==================================================\n",
      "üìÇ Cargando datasets...\n",
      "   üîÑ Creando dataset train...\n",
      "   ‚úÖ Dataset train creado: 9000 im√°genes\n",
      "   üîÑ Creando dataset val...\n",
      "   ‚úÖ Dataset val creado: 3000 im√°genes\n",
      "   üîÑ Creando dataset test...\n",
      "   ‚úÖ Dataset test creado: 3000 im√°genes\n",
      "üìä Dataset: Train=9000, Val=3000, Test=3000 | 30 clases\n",
      "üéØ Objetivo: Superar baseline de 0.7404 validation loss\n",
      "üíª Device: CUDA\n",
      "‚è±Ô∏è Tiempo estimado: 2-3 horas para 15 trials\n",
      "üöÄ Iniciando optimizaci√≥n...\n",
      "\n",
      "üîç Trial 1/15\n",
      "   üìä Par√°metros: lr=0.00016, bs=16, epochs=5, dropout=0.7\n",
      "   üéØ Baseline a superar: 0.7404 val_loss\n",
      "   üöÄ Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=3.2926(11.5%) | Val=2.8234(29.6%) ‚¨ÜÔ∏è\n",
      "   üèÜ ¬°NUEVO R√âCORD GLOBAL! Val Loss: 2.823425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=2.7218(25.0%) | Val=2.0948(49.8%) ‚¨ÜÔ∏è\n",
      "   üèÜ ¬°NUEVO R√âCORD GLOBAL! Val Loss: 2.094762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=2.1305(40.5%) | Val=1.5749(62.9%) ‚¨ÜÔ∏è\n",
      "   üèÜ ¬°NUEVO R√âCORD GLOBAL! Val Loss: 1.574946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 4: Train=1.6557(53.1%) | Val=1.2022(72.7%) ‚¨ÜÔ∏è\n",
      "   üèÜ ¬°NUEVO R√âCORD GLOBAL! Val Loss: 1.202243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5: Train=1.2677(63.5%) | Val=0.9807(76.3%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 17:23:02,814] Trial 0 finished with value: 0.9807264020349434 and parameters: {'learning_rate': 0.00016184352923539398, 'batch_size': 16, 'num_epochs': 5, 'dropout': 0.7}. Best is trial 0 with value: 0.9807264020349434.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üèÜ ¬°NUEVO R√âCORD GLOBAL! Val Loss: 0.980726\n",
      "   ‚úÖ COMPLETADO - Mejor Val Loss: 0.980726 (Decline: -32.47%)\n",
      "\n",
      "üîç Trial 2/15\n",
      "   üìä Par√°metros: lr=0.00041, bs=32, epochs=3, dropout=0.6\n",
      "   üéØ Baseline a superar: 0.7404 val_loss\n",
      "   üöÄ Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=3.1473(17.1%) | Val=2.3269(40.9%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=2.1319(41.8%) | Val=1.5345(64.0%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 17:25:24,750] Trial 1 finished with value: 0.9952572820351478 and parameters: {'learning_rate': 0.0004111164009367583, 'batch_size': 32, 'num_epochs': 3, 'dropout': 0.6000000000000001}. Best is trial 0 with value: 0.9807264020349434.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=1.3524(63.2%) | Val=0.9953(76.2%) ‚¨ÜÔ∏è\n",
      "   ‚úÖ COMPLETADO - Mejor Val Loss: 0.995257 (Decline: -34.43%)\n",
      "\n",
      "üîç Trial 3/15\n",
      "   üìä Par√°metros: lr=0.00087, bs=64, epochs=4, dropout=0.5\n",
      "   üéØ Baseline a superar: 0.7404 val_loss\n",
      "   üöÄ Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=3.9823(4.6%) | Val=3.3400(8.0%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=3.1657(13.8%) | Val=2.7009(27.0%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=2.4849(32.0%) | Val=1.9959(51.1%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 17:28:50,546] Trial 2 finished with value: 1.3102737411539604 and parameters: {'learning_rate': 0.0008733109432600577, 'batch_size': 64, 'num_epochs': 4, 'dropout': 0.5}. Best is trial 0 with value: 0.9807264020349434.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 4: Train=1.7023(53.6%) | Val=1.3103(67.9%) ‚¨ÜÔ∏è\n",
      "   ‚úÖ COMPLETADO - Mejor Val Loss: 1.310274 (Decline: -76.98%)\n",
      "\n",
      "üîç Trial 4/15\n",
      "   üìä Par√°metros: lr=0.00016, bs=48, epochs=7, dropout=0.7\n",
      "   üéØ Baseline a superar: 0.7404 val_loss\n",
      "   üöÄ Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=3.4545(6.5%) | Val=3.1746(18.4%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=3.1610(12.8%) | Val=2.8845(25.2%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 17:31:11,336] Trial 3 pruned.                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=2.8557(20.3%) | Val=2.4268(39.8%) ‚¨ÜÔ∏è\n",
      "   ‚úÇÔ∏è Trial podado - no es prometedor\n",
      "\n",
      "üîç Trial 5/15\n",
      "   üìä Par√°metros: lr=0.00028, bs=32, epochs=3, dropout=0.3\n",
      "   üéØ Baseline a superar: 0.7404 val_loss\n",
      "   üöÄ Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=3.0297(20.3%) | Val=2.2238(41.2%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=1.9280(47.8%) | Val=1.3809(66.1%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 17:33:39,147] Trial 4 finished with value: 1.0006311938483665 and parameters: {'learning_rate': 0.00027513661756959414, 'batch_size': 32, 'num_epochs': 3, 'dropout': 0.3}. Best is trial 0 with value: 0.9807264020349434.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=1.0641(70.7%) | Val=1.0006(75.4%) ‚¨ÜÔ∏è\n",
      "   ‚úÖ COMPLETADO - Mejor Val Loss: 1.000631 (Decline: -35.16%)\n",
      "\n",
      "üîç Trial 6/15\n",
      "   üìä Par√°metros: lr=0.00011, bs=16, epochs=6, dropout=0.7\n",
      "   üéØ Baseline a superar: 0.7404 val_loss\n",
      "   üöÄ Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=3.4135(6.5%) | Val=3.1625(18.0%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=3.0462(16.0%) | Val=2.6564(34.9%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 17:36:16,167] Trial 5 pruned.                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=2.6549(25.9%) | Val=2.1944(48.2%) ‚¨ÜÔ∏è\n",
      "   ‚úÇÔ∏è Trial podado - no es prometedor\n",
      "\n",
      "üîç Trial 7/15\n",
      "   üìä Par√°metros: lr=0.00023, bs=16, epochs=8, dropout=0.5\n",
      "   üéØ Baseline a superar: 0.7404 val_loss\n",
      "   üöÄ Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=2.9270(22.8%) | Val=1.9858(49.8%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=1.7653(51.2%) | Val=1.1909(70.9%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.9791(72.6%) | Val=0.8644(79.3%) ‚¨ÜÔ∏è\n",
      "   üèÜ ¬°NUEVO R√âCORD GLOBAL! Val Loss: 0.864383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 4: Train=0.5441(85.0%) | Val=0.7918(81.9%) ‚¨ÜÔ∏è\n",
      "   üèÜ ¬°NUEVO R√âCORD GLOBAL! Val Loss: 0.791789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5: Train=0.3720(89.9%) | Val=0.7945(81.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 6: Train=0.2831(92.5%) | Val=0.7832(82.5%) ‚¨ÜÔ∏è\n",
      "   üèÜ ¬°NUEVO R√âCORD GLOBAL! Val Loss: 0.783237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 7: Train=0.2492(94.1%) | Val=0.8005(82.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 8: Train=0.2039(95.0%) | Val=0.7614(83.2%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 17:43:14,235] Trial 6 finished with value: 0.7613552343313944 and parameters: {'learning_rate': 0.00023117485061294573, 'batch_size': 16, 'num_epochs': 8, 'dropout': 0.5}. Best is trial 6 with value: 0.7613552343313944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üèÜ ¬°NUEVO R√âCORD GLOBAL! Val Loss: 0.761355\n",
      "   ‚úÖ COMPLETADO - Mejor Val Loss: 0.761355 (Decline: -2.84%)\n",
      "\n",
      "üîç Trial 8/15\n",
      "   üìä Par√°metros: lr=0.00043, bs=24, epochs=8, dropout=0.4\n",
      "   üéØ Baseline a superar: 0.7404 val_loss\n",
      "   üöÄ Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=3.1004(22.1%) | Val=2.0469(45.1%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=1.7304(52.7%) | Val=1.2095(69.8%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.8336(76.9%) | Val=0.8509(79.2%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 4: Train=0.4292(89.1%) | Val=0.8462(80.9%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5: Train=0.2923(92.6%) | Val=0.8115(81.5%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 17:47:58,628] Trial 7 pruned.                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 6: Train=0.2312(94.4%) | Val=0.8334(82.0%)\n",
      "   ‚úÇÔ∏è Trial podado - no es prometedor\n",
      "\n",
      "üîç Trial 9/15\n",
      "   üìä Par√°metros: lr=0.00025, bs=16, epochs=8, dropout=0.5\n",
      "   üéØ Baseline a superar: 0.7404 val_loss\n",
      "   üöÄ Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=3.0912(18.3%) | Val=2.1999(43.1%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=2.0090(45.4%) | Val=1.3787(65.8%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=1.1800(66.6%) | Val=0.9452(77.5%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 4: Train=0.6596(81.2%) | Val=0.8094(80.6%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5: Train=0.4125(89.0%) | Val=0.7540(82.1%) ‚¨ÜÔ∏è\n",
      "   üèÜ ¬°NUEVO R√âCORD GLOBAL! Val Loss: 0.753959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 6: Train=0.3138(92.2%) | Val=0.7244(82.1%) üéâ\n",
      "   üèÜ ¬°NUEVO R√âCORD GLOBAL! Val Loss: 0.724403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 7: Train=0.2420(93.7%) | Val=0.7859(82.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 17:54:47,814] Trial 8 finished with value: 0.7244033061743199 and parameters: {'learning_rate': 0.0002482301862794532, 'batch_size': 16, 'num_epochs': 8, 'dropout': 0.5}. Best is trial 8 with value: 0.7244033061743199.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 8: Train=0.2213(94.5%) | Val=0.7925(82.6%)\n",
      "   ‚úÖ COMPLETADO - Mejor Val Loss: 0.724403 (Mejora: +2.15%)\n",
      "\n",
      "üîç Trial 10/15\n",
      "   üìä Par√°metros: lr=0.00085, bs=64, epochs=6, dropout=0.3\n",
      "   üéØ Baseline a superar: 0.7404 val_loss\n",
      "   üöÄ Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=3.4787(15.5%) | Val=2.5883(28.9%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=2.3440(35.6%) | Val=1.8630(50.4%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 17:57:20,311] Trial 9 pruned.                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=1.5917(55.7%) | Val=1.2944(67.9%) ‚¨ÜÔ∏è\n",
      "   ‚úÇÔ∏è Trial podado - no es prometedor\n",
      "\n",
      "üîç Trial 11/15\n",
      "   üìä Par√°metros: lr=0.00054, bs=24, epochs=7, dropout=0.5\n",
      "   üéØ Baseline a superar: 0.7404 val_loss\n",
      "   üöÄ Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=3.0329(21.2%) | Val=2.1391(44.9%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=1.8894(48.7%) | Val=1.3047(67.9%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=1.0308(71.1%) | Val=0.9354(77.3%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 4: Train=0.5725(84.2%) | Val=0.8574(80.3%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 18:01:12,241] Trial 10 pruned.                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5: Train=0.4080(89.5%) | Val=0.8267(80.8%) ‚¨ÜÔ∏è\n",
      "   ‚úÇÔ∏è Trial podado - no es prometedor\n",
      "\n",
      "üîç Trial 12/15\n",
      "   üìä Par√°metros: lr=0.00021, bs=16, epochs=8, dropout=0.5\n",
      "   üéØ Baseline a superar: 0.7404 val_loss\n",
      "   üöÄ Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=3.1503(17.5%) | Val=2.3204(40.8%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=2.1454(41.4%) | Val=1.5275(61.1%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 18:03:47,489] Trial 11 pruned.                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=1.3401(62.6%) | Val=1.0917(75.6%) ‚¨ÜÔ∏è\n",
      "   ‚úÇÔ∏è Trial podado - no es prometedor\n",
      "\n",
      "üîç Trial 13/15\n",
      "   üìä Par√°metros: lr=0.00027, bs=16, epochs=8, dropout=0.4\n",
      "   üéØ Baseline a superar: 0.7404 val_loss\n",
      "   üöÄ Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=2.9247(22.4%) | Val=2.0604(49.3%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=1.7644(52.1%) | Val=1.2537(70.1%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.9043(74.9%) | Val=0.8778(79.0%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 4: Train=0.4768(87.5%) | Val=0.7972(81.1%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 18:08:06,502] Trial 12 pruned.                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5: Train=0.2982(92.0%) | Val=0.7967(82.8%) ‚¨ÜÔ∏è\n",
      "   ‚úÇÔ∏è Trial podado - no es prometedor\n",
      "\n",
      "üîç Trial 14/15\n",
      "   üìä Par√°metros: lr=0.00019, bs=16, epochs=7, dropout=0.6\n",
      "   üéØ Baseline a superar: 0.7404 val_loss\n",
      "   üöÄ Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=3.0098(18.9%) | Val=2.2734(44.2%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=2.0735(43.7%) | Val=1.4541(64.2%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 18:10:44,838] Trial 13 pruned.                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=1.3274(63.1%) | Val=1.0245(75.7%) ‚¨ÜÔ∏è\n",
      "   ‚úÇÔ∏è Trial podado - no es prometedor\n",
      "\n",
      "üîç Trial 15/15\n",
      "   üìä Par√°metros: lr=0.00012, bs=48, epochs=8, dropout=0.4\n",
      "   üéØ Baseline a superar: 0.7404 val_loss\n",
      "   üöÄ Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=3.3331(11.4%) | Val=2.7691(25.6%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=2.6745(26.7%) | Val=2.2870(41.2%) ‚¨ÜÔ∏è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 18:13:13,441] Trial 14 pruned.                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=2.2345(38.8%) | Val=1.8930(49.9%) ‚¨ÜÔ∏è\n",
      "   ‚úÇÔ∏è Trial podado - no es prometedor\n",
      "\n",
      "============================================================\n",
      "üéâ OPTIMIZACI√ìN COMPLETADA\n",
      "============================================================\n",
      "üèÜ MEJOR RESULTADO:\n",
      "   üìä Validation Loss: 0.724403\n",
      "   ‚öôÔ∏è Par√°metros: {'learning_rate': 0.0002482301862794532, 'batch_size': 16, 'num_epochs': 8, 'dropout': 0.5}\n",
      "   üî¢ Trial n√∫mero: 8\n",
      "   üìà ¬°MEJORA vs baseline!: +2.15%\n",
      "\n",
      "üìà Resumen de trials:\n",
      "   ‚úÖ Trials completados: 15\n",
      "   ‚úÇÔ∏è Trials podados: 9\n",
      "   ‚ùå Trials fallidos: 0\n",
      "\n",
      "üß™ EVALUACI√ìN EN TEST SET:\n",
      "----------------------------------------\n",
      "üîç Evaluando modelo en dataset de test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluaci√≥n: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 94/94 [00:09<00:00, 10.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Test Loss: 0.761791\n",
      "üéØ Test Accuracy: 82.43%\n",
      "\n",
      "üíæ GENERANDO INFORMES:\n",
      "----------------------------------------\n",
      "üìä Matriz de confusi√≥n guardada en: best_model_confusion_matrix.png\n",
      "üìÑ Informe completo guardado en: optimization_report.json\n",
      "üìà Gr√°fico de optimizaci√≥n guardado en: optimization_history.png\n",
      "‚úÖ Archivos generados:\n",
      "   üì¶ optimized_best_model.pth - Mejor modelo\n",
      "   üìä best_model_confusion_matrix.png - Matriz de confusi√≥n\n",
      "   üìÑ optimization_report.json - Informe completo\n",
      "   üìà optimization_history.png - Historia de optimizaci√≥n\n",
      "\n",
      "üéä ¬°PROCESO COMPLETADO EXITOSAMENTE!\n",
      "\n",
      "üí° RECOMENDACIONES:\n",
      "----------------------------------------\n",
      "‚úÖ ¬°Excelente! Se encontr√≥ una mejora significativa.\n",
      "   Considera ejecutar m√°s trials alrededor de estos par√°metros.\n",
      "\n",
      "üèÅ FIN DEL PROCESO\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Dataset Class\n",
    "class WasteDataset(Dataset):\n",
    "    def __init__(self, root_dir, split, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        print(f\"   üîÑ Creando dataset {split}...\")\n",
    "        \n",
    "        for i, class_name in enumerate(self.classes):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            for subfolder in ['default', 'real_world']:\n",
    "                subfolder_dir = os.path.join(class_dir, subfolder)\n",
    "                if not os.path.exists(subfolder_dir):\n",
    "                    continue\n",
    "                    \n",
    "                image_names = [f for f in os.listdir(subfolder_dir) \n",
    "                             if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "                random.shuffle(image_names)\n",
    "                \n",
    "                if split == 'train':\n",
    "                    image_names = image_names[:int(0.6 * len(image_names))]\n",
    "                elif split == 'val':\n",
    "                    image_names = image_names[int(0.6 * len(image_names)):int(0.8 * len(image_names))]\n",
    "                else:  # test\n",
    "                    image_names = image_names[int(0.8 * len(image_names)):]\n",
    "                \n",
    "                for image_name in image_names:\n",
    "                    self.image_paths.append(os.path.join(subfolder_dir, image_name))\n",
    "                    self.labels.append(i)\n",
    "        \n",
    "        print(f\"   ‚úÖ Dataset {split} creado: {len(self.image_paths)} im√°genes\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        label = self.labels[index]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# CNN Model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 56 * 56, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device, class_names):\n",
    "    \"\"\"Eval√∫a el modelo y retorna m√©tricas detalladas\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    print(\"üîç Evaluando modelo en dataset de test...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Evaluaci√≥n\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_loss = total_loss / len(test_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return {\n",
    "        'test_loss': test_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': all_preds,\n",
    "        'true_labels': all_labels,\n",
    "        'classification_report': classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, save_path='confusion_matrix.png'):\n",
    "    \"\"\"Genera y guarda la matriz de confusi√≥n\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Matriz de Confusi√≥n - Mejor Modelo', fontsize=16)\n",
    "    plt.ylabel('Etiquetas Verdaderas', fontsize=12)\n",
    "    plt.xlabel('Predicciones', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"üìä Matriz de confusi√≥n guardada en: {save_path}\")\n",
    "\n",
    "def generate_report(study, best_metrics, class_names, save_path='optimization_report.json'):\n",
    "    \"\"\"Genera un informe completo de la optimizaci√≥n\"\"\"\n",
    "    report = {\n",
    "        'optimization_info': {\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'n_trials': len(study.trials),\n",
    "            'best_trial_number': study.best_trial.number,\n",
    "            'optimization_direction': 'minimize_validation_loss'\n",
    "        },\n",
    "        'best_hyperparameters': study.best_trial.params,\n",
    "        'best_validation_loss': study.best_trial.value,\n",
    "        'test_metrics': {\n",
    "            'test_loss': best_metrics['test_loss'],\n",
    "            'test_accuracy': best_metrics['accuracy']\n",
    "        },\n",
    "        'classification_report': best_metrics['classification_report'],\n",
    "        'trial_history': [\n",
    "            {\n",
    "                'trial': t.number,\n",
    "                'params': t.params,\n",
    "                'value': t.value,\n",
    "                'state': str(t.state)\n",
    "            } for t in study.trials if t.value is not None\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    with open(save_path, 'w') as f:\n",
    "        json.dump(report, f, indent=2)\n",
    "    \n",
    "    print(f\"üìÑ Informe completo guardado en: {save_path}\")\n",
    "    return report\n",
    "\n",
    "def plot_optimization_history(study, save_path='optimization_history.png'):\n",
    "    \"\"\"Genera gr√°fico de la historia de optimizaci√≥n\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Historia de valores\n",
    "    trial_numbers = [t.number for t in study.trials if t.value is not None]\n",
    "    values = [t.value for t in study.trials if t.value is not None]\n",
    "    \n",
    "    ax1.plot(trial_numbers, values, 'b-o', markersize=4)\n",
    "    ax1.axhline(y=study.best_value, color='r', linestyle='--', label=f'Mejor: {study.best_value:.4f}')\n",
    "    ax1.set_xlabel('Trial')\n",
    "    ax1.set_ylabel('Validation Loss')\n",
    "    ax1.set_title('Historia de Optimizaci√≥n')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Distribuci√≥n de valores\n",
    "    ax2.hist(values, bins=min(20, len(values)), alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    ax2.axvline(x=study.best_value, color='r', linestyle='--', label=f'Mejor: {study.best_value:.4f}')\n",
    "    ax2.set_xlabel('Validation Loss')\n",
    "    ax2.set_ylabel('Frecuencia')\n",
    "    ax2.set_title('Distribuci√≥n de Resultados')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"üìà Gr√°fico de optimizaci√≥n guardado en: {save_path}\")\n",
    "\n",
    "# Configuraci√≥n\n",
    "print(\"üöÄ INICIANDO OPTUNA HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Initialize datasets\n",
    "print(\"üìÇ Cargando datasets...\")\n",
    "dataset_path = 'images'\n",
    "train_dataset = WasteDataset(dataset_path, 'train', transform)\n",
    "val_dataset = WasteDataset(dataset_path, 'val', transform)\n",
    "test_dataset = WasteDataset(dataset_path, 'test', transform)\n",
    "print(f\"üìä Dataset: Train={len(train_dataset)}, Val={len(val_dataset)}, Test={len(test_dataset)} | {len(train_dataset.classes)} clases\")\n",
    "\n",
    "# Variables globales para tracking\n",
    "best_global_loss = float('inf')\n",
    "best_model_state = None\n",
    "trial_count = 0\n",
    "\n",
    "def objective(trial):\n",
    "    global best_global_loss, best_model_state, trial_count\n",
    "    trial_count += 1\n",
    "    \n",
    "    # Hiperpar√°metros centrados alrededor de tu mejor combinaci√≥n\n",
    "    # Learning rate: centrado en 0.0005 con variaci√≥n\n",
    "    lr = trial.suggest_float('learning_rate', 0.0001, 0.001, log=True)\n",
    "    \n",
    "    # Batch size: probamos tama√±os alrededor de 32\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 24, 32, 48, 64])\n",
    "    \n",
    "    # Epochs: mantenemos bajo para evitar overfitting, centrado en 5\n",
    "    epochs = trial.suggest_int('num_epochs', 3, 8)\n",
    "    \n",
    "    # Dropout: experimentamos con diferentes valores\n",
    "    dropout = trial.suggest_float('dropout', 0.3, 0.7, step=0.1)\n",
    "    \n",
    "    print(f\"\\nüîç Trial {trial_count}/{15}\")\n",
    "    print(f\"   üìä Par√°metros: lr={lr:.5f}, bs={batch_size}, epochs={epochs}, dropout={dropout:.1f}\")\n",
    "    print(f\"   üéØ Baseline a superar: 0.7404 val_loss\")\n",
    "    \n",
    "    # Crear DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=False)\n",
    "    \n",
    "    # Model setup con dropout personalizable\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = CNN(len(train_dataset.classes)).to(device)\n",
    "    \n",
    "    # Modificar dropout del modelo\n",
    "    model.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    patience = 3  # Paciencia para early stopping\n",
    "    \n",
    "    print(f\"   üöÄ Iniciando entrenamiento...\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        train_bar = tqdm(train_loader, desc=f\"   Epoch {epoch+1}/{epochs} [Train]\", leave=False)\n",
    "        for images, labels in train_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Actualizar barra de progreso\n",
    "            current_train_loss = train_loss / (train_bar.n + 1)\n",
    "            current_train_acc = 100. * train_correct / train_total\n",
    "            train_bar.set_postfix({'Loss': f'{current_train_loss:.4f}', 'Acc': f'{current_train_acc:.1f}%'})\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_accuracy = 100. * train_correct / train_total\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(val_loader, desc=f\"   Epoch {epoch+1}/{epochs} [Val]  \", leave=False)\n",
    "            for images, labels in val_bar:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # Actualizar barra de progreso\n",
    "                current_val_loss = val_loss / (val_bar.n + 1)\n",
    "                current_val_acc = 100. * val_correct / val_total\n",
    "                val_bar.set_postfix({'Loss': f'{current_val_loss:.4f}', 'Acc': f'{current_val_acc:.1f}%'})\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100. * val_correct / val_total\n",
    "        \n",
    "        # Mostrar resultados del epoch\n",
    "        improvement_indicator = \"\"\n",
    "        if avg_val_loss < 0.7404:\n",
    "            improvement_indicator = \" üéâ\"\n",
    "        elif avg_val_loss < best_val_loss:\n",
    "            improvement_indicator = \" ‚¨ÜÔ∏è\"\n",
    "        \n",
    "        print(f\"   Epoch {epoch+1}: Train={avg_train_loss:.4f}({train_accuracy:.1f}%) | Val={avg_val_loss:.4f}({val_accuracy:.1f}%){improvement_indicator}\")\n",
    "        \n",
    "        # Report intermediate result para pruning\n",
    "        trial.report(avg_val_loss, epoch)\n",
    "        \n",
    "        # Prune si no es prometedor\n",
    "        if trial.should_prune():\n",
    "            print(f\"   ‚úÇÔ∏è Trial podado - no es prometedor\")\n",
    "            raise optuna.TrialPruned()\n",
    "        \n",
    "        # Update best validation loss\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # Si es el mejor modelo global, guardarlo\n",
    "            if avg_val_loss < best_global_loss:\n",
    "                best_global_loss = avg_val_loss\n",
    "                best_model_state = model.state_dict().copy()\n",
    "                torch.save(best_model_state, 'best_model_temp.pth')\n",
    "                print(f\"   üèÜ ¬°NUEVO R√âCORD GLOBAL! Val Loss: {avg_val_loss:.6f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"   ‚è∞ Early stopping (sin mejora por {patience} epochs)\")\n",
    "            break\n",
    "    \n",
    "    # Calcular mejora respecto al baseline\n",
    "    baseline_loss = 0.7403552888731162\n",
    "    if best_val_loss < baseline_loss:\n",
    "        improvement = ((baseline_loss - best_val_loss) / baseline_loss) * 100\n",
    "        print(f\"   ‚úÖ COMPLETADO - Mejor Val Loss: {best_val_loss:.6f} (Mejora: +{improvement:.2f}%)\")\n",
    "    else:\n",
    "        decline = ((best_val_loss - baseline_loss) / baseline_loss) * 100\n",
    "        print(f\"   ‚úÖ COMPLETADO - Mejor Val Loss: {best_val_loss:.6f} (Decline: -{decline:.2f}%)\")\n",
    "    \n",
    "    # Cleanup\n",
    "    del model, train_loader, val_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return best_val_loss\n",
    "\n",
    "# Crear estudio de Optuna\n",
    "print(f\"üéØ Objetivo: Superar baseline de 0.7404 validation loss\")\n",
    "print(f\"üíª Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"‚è±Ô∏è Tiempo estimado: 2-3 horas para 15 trials\")\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=optuna.samplers.TPESampler(n_startup_trials=5),  # M√°s trials iniciales para mejor exploraci√≥n\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=3, n_warmup_steps=2)\n",
    ")\n",
    "\n",
    "# Ejecutar optimizaci√≥n\n",
    "print(\"üöÄ Iniciando optimizaci√≥n...\")\n",
    "try:\n",
    "    study.optimize(objective, n_trials=15, timeout=10800)  # 15 trials, 3h max\n",
    "    optimization_completed = True\n",
    "except KeyboardInterrupt:\n",
    "    print(\"‚è∏Ô∏è Interrumpido por usuario\")\n",
    "    optimization_completed = True\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error durante optimizaci√≥n: {e}\")\n",
    "    optimization_completed = False\n",
    "\n",
    "# Resultados finales\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ OPTIMIZACI√ìN COMPLETADA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(study.trials) > 0 and study.best_trial:\n",
    "    print(f\"üèÜ MEJOR RESULTADO:\")\n",
    "    print(f\"   üìä Validation Loss: {study.best_trial.value:.6f}\")\n",
    "    print(f\"   ‚öôÔ∏è Par√°metros: {study.best_trial.params}\")\n",
    "    print(f\"   üî¢ Trial n√∫mero: {study.best_trial.number}\")\n",
    "    \n",
    "    baseline_loss = 0.7403552888731162\n",
    "    if study.best_trial.value < baseline_loss:\n",
    "        improvement = ((baseline_loss - study.best_trial.value) / baseline_loss) * 100\n",
    "        print(f\"   üìà ¬°MEJORA vs baseline!: +{improvement:.2f}%\")\n",
    "    else:\n",
    "        decline = ((study.best_trial.value - baseline_loss) / baseline_loss) * 100\n",
    "        print(f\"   üìâ Decline vs baseline: -{decline:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nüìà Resumen de trials:\")\n",
    "    print(f\"   ‚úÖ Trials completados: {len([t for t in study.trials if t.value is not None])}\")\n",
    "    print(f\"   ‚úÇÔ∏è Trials podados: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}\")\n",
    "    print(f\"   ‚ùå Trials fallidos: {len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])}\")\n",
    "    \n",
    "    # Evaluar el mejor modelo en test set\n",
    "    if os.path.exists('best_model_temp.pth'):\n",
    "        print(f\"\\nüß™ EVALUACI√ìN EN TEST SET:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        best_model = CNN(len(train_dataset.classes)).to(device)\n",
    "        best_model.load_state_dict(torch.load('best_model_temp.pth'))\n",
    "        \n",
    "        # Aplicar dropout del mejor trial\n",
    "        if 'dropout' in study.best_trial.params:\n",
    "            best_model.dropout = nn.Dropout(study.best_trial.params['dropout'])\n",
    "        \n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        test_metrics = evaluate_model(best_model, test_loader, criterion, device, train_dataset.classes)\n",
    "        \n",
    "        print(f\"üìä Test Loss: {test_metrics['test_loss']:.6f}\")\n",
    "        print(f\"üéØ Test Accuracy: {test_metrics['accuracy']*100:.2f}%\")\n",
    "        \n",
    "        # Generar todos los informes y gr√°ficos\n",
    "        print(f\"\\nüíæ GENERANDO INFORMES:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        plot_confusion_matrix(test_metrics['true_labels'], test_metrics['predictions'], \n",
    "                            train_dataset.classes, 'best_model_confusion_matrix.png')\n",
    "        \n",
    "        generate_report(study, test_metrics, train_dataset.classes, 'optimization_report.json')\n",
    "        \n",
    "        plot_optimization_history(study, 'optimization_history.png')\n",
    "        \n",
    "        # Guardar modelo final\n",
    "        torch.save(best_model.state_dict(), \"optimized_best_model.pth\")\n",
    "        \n",
    "        print(\"‚úÖ Archivos generados:\")\n",
    "        print(\"   üì¶ optimized_best_model.pth - Mejor modelo\")\n",
    "        print(\"   üìä best_model_confusion_matrix.png - Matriz de confusi√≥n\")\n",
    "        print(\"   üìÑ optimization_report.json - Informe completo\")\n",
    "        print(\"   üìà optimization_history.png - Historia de optimizaci√≥n\")\n",
    "        \n",
    "        # Limpiar archivo temporal\n",
    "        if os.path.exists('best_model_temp.pth'):\n",
    "            os.remove('best_model_temp.pth')\n",
    "        \n",
    "        print(f\"\\nüéä ¬°PROCESO COMPLETADO EXITOSAMENTE!\")\n",
    "        \n",
    "        # Mostrar recomendaciones\n",
    "        print(f\"\\nüí° RECOMENDACIONES:\")\n",
    "        print(\"-\" * 40)\n",
    "        if study.best_trial.value < baseline_loss:\n",
    "            print(\"‚úÖ ¬°Excelente! Se encontr√≥ una mejora significativa.\")\n",
    "            print(\"   Considera ejecutar m√°s trials alrededor de estos par√°metros.\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No se super√≥ el baseline actual.\")\n",
    "            print(\"   Considera probar:\")\n",
    "            print(\"   - Rangos de learning rate m√°s amplios\")\n",
    "            print(\"   - M√°s epochs con regularizaci√≥n\")\n",
    "            print(\"   - Arquitecturas de modelo diferentes\")\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No se encontr√≥ el modelo guardado\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No se completaron trials exitosos\")\n",
    "    print(\"üîß Verifica:\")\n",
    "    print(\"   - Ruta del dataset\")\n",
    "    print(\"   - Memoria GPU disponible\")\n",
    "    print(\"   - Configuraci√≥n de hiperpar√°metros\")\n",
    "\n",
    "print(\"\\nüèÅ FIN DEL PROCESO\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
