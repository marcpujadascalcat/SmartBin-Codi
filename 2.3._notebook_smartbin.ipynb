{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faddcebd-64b1-489f-bcd2-ebd1f0770af2",
   "metadata": {},
   "source": [
    "# âš™ï¸ SmartBin â€” OptimitzaciÃ³ amb Transfer Learning i Optuna *(VersiÃ³ 2.3)*\n",
    "\n",
    "> **Aquest notebook ha estat generat amb assistÃ¨ncia dâ€™intelÂ·ligÃ¨ncia artificial, perÃ² totes les decisions sobre les tÃ¨cniques i metodologies utilitzades han estat preses per una persona humana.**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§© DescripciÃ³ general\n",
    "\n",
    "Aquesta versiÃ³ del projecte **SmartBin** implementa un sistema complet de **classificaciÃ³ dâ€™imatges de residus** basat en **Transfer Learning** amb el model **ResNet18**, optimitzat automÃ ticament mitjanÃ§ant **Optuna**.  \n",
    "El notebook combina tÃ¨cniques avanÃ§ades dâ€™augmentaciÃ³ de dades, balanceig de classes i optimitzaciÃ³ dâ€™hiperparÃ metres per obtenir un model robust, eficient i capaÃ§ de generalitzar bÃ© en diferents condicions visuals.\n",
    "\n",
    "El sistema estÃ  dissenyat per classificar **sis categories de residus**:\n",
    "- **PlÃ stics**\n",
    "- **Metalls**\n",
    "- **Paper**\n",
    "- **Vidre**\n",
    "- **OrgÃ nic**\n",
    "- **TÃ¨xtil**\n",
    "\n",
    "Aquest enfocament permet al SmartBin reconÃ¨ixer una gamma mÃ©s Ã mplia de materials, millorant aixÃ­ la seva capacitat de gestiÃ³ selectiva i el seu potencial dâ€™Ãºs real.\n",
    "\n",
    "> **Dataset utilitzat:** [Recyclable and Household Waste Classification (Kaggle)](https://www.kaggle.com/datasets/alistairking/recyclable-and-household-waste-classification)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Objectiu del projecte\n",
    "\n",
    "Lâ€™objectiu dâ€™aquesta versiÃ³ Ã©s **millorar significativament la precisiÃ³ de classificaciÃ³** respecte a les versions anteriors, aprofitant els avantatges del *transfer learning* i lâ€™optimitzaciÃ³ automÃ tica dâ€™hiperparÃ metres.  \n",
    "En concret, es busca reduir la pÃ¨rdua de validaciÃ³ i augmentar el F1-score mitjanÃ§ant:\n",
    "\n",
    "- **Transfer Learning amb ResNet18:** utilitzant pesos preentrenats sobre ImageNet per accelerar lâ€™aprenentatge.  \n",
    "- **AugmentaciÃ³ selectiva de dades:** per incrementar la representaciÃ³ de classes minoritÃ ries (*vidre* i *tÃ¨xtil*).  \n",
    "- **Pesatge de classes (WeightedRandomSampler):** per compensar desequilibris en la distribuciÃ³ del dataset.  \n",
    "- **Entrenament amb pruning i early stopping:** que milloren lâ€™eficiÃ¨ncia i eviten sobreajustament.  \n",
    "- **GeneraciÃ³ automÃ tica dâ€™informes:** amb mÃ¨triques, matrius de confusiÃ³ i histÃ²rics dâ€™optimitzaciÃ³.\n",
    "\n",
    "Aquest conjunt dâ€™estratÃ¨gies permet obtenir un model **mÃ©s precÃ­s, equilibrat i escalable**, preparat per a aplicacions en entorns fÃ­sics reals.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ—‚ï¸ Dataset i preparaciÃ³ de dades\n",
    "\n",
    "El dataset sâ€™organitza en **carpetes per classe**, seguint una estructura simple i funcional.  \n",
    "La divisiÃ³ sâ€™ha realitzat de manera automÃ tica en tres subconjunts:\n",
    "\n",
    "- **60% entrenament**  \n",
    "- **20% validaciÃ³**  \n",
    "- **20% test**\n",
    "\n",
    "Durant el preprocessament sâ€™apliquen transformacions especÃ­fiques:\n",
    "\n",
    "- **Entrenament:**  \n",
    "  - Rotacions aleatÃ²ries, reflexions horitzontals, canvis de color i recadrament aleatori.  \n",
    "  - AugmentaciÃ³ extra per a les classes menys representades (*vidre* i *tÃ¨xtil*).  \n",
    "\n",
    "- **ValidaciÃ³ i Test:**  \n",
    "  - Redimensionament a 224Ã—224 pÃ­xels i normalitzaciÃ³ segons els valors estÃ ndard dâ€™ImageNet.\n",
    "\n",
    "A mÃ©s, sâ€™empra un **WeightedRandomSampler** per assegurar que totes les classes tinguin una presÃ¨ncia equilibrada durant lâ€™entrenament, evitant que el model sâ€™inclini cap a categories majoritÃ ries.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Arquitectura del model: ResNet18 amb Transfer Learning\n",
    "\n",
    "El model base Ã©s una **ResNet18** preentrenada amb milions dâ€™imatges dâ€™ImageNet.  \n",
    "MitjanÃ§ant *transfer learning*, sâ€™aprofiten les primeres capes per conservar el coneixement general de caracterÃ­stiques visuals, adaptant nomÃ©s les Ãºltimes capes a la nova tasca de classificaciÃ³ de residus.\n",
    "\n",
    "Lâ€™estratÃ¨gia aplicada Ã©s la segÃ¼ent:\n",
    "\n",
    "- **CongelaciÃ³ parcial de capes:**  \n",
    "  Les primeres capes convolucionals (`conv1`, `bn1`, `layer1`, `layer2`) es mantenen fixes per conservar els pesos preapresos.  \n",
    "\n",
    "- **Desbloqueig selectiu:**  \n",
    "  Les capes superiors (`layer3`, `layer4` i `fc`) es reentrenen per aprendre patrons especÃ­fics del nou dataset.\n",
    "\n",
    "- **Capa de sortida modificada:**  \n",
    "  Sâ€™adapta la capa final fully connected per generar **6 classes** de sortida.\n",
    "\n",
    "- **Dropout ajustable:**  \n",
    "  Per reduir lâ€™overfitting, es permet optimitzar el valor de *dropout* durant la cerca dâ€™hiperparÃ metres.\n",
    "\n",
    "Aquesta combinaciÃ³ permet **reduir el temps dâ€™entrenament** i **millorar la precisiÃ³ final** amb un Ãºs eficient de recursos.\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ OptimitzaciÃ³ automÃ tica amb Optuna\n",
    "\n",
    "Per ajustar els hiperparÃ metres, sâ€™utilitza la llibreria **Optuna**, que realitza una optimitzaciÃ³ automÃ tica basada en tÃ¨cniques dâ€™estimaciÃ³ bayesiana i pruning adaptatiu.  \n",
    "Cada *trial* representa un entrenament complet del model amb una combinaciÃ³ diferent dâ€™hiperparÃ metres, buscant **minimitzar la pÃ¨rdua de validaciÃ³ (validation loss)**.\n",
    "\n",
    "| HiperparÃ metre | Rang o valors explorats |\n",
    "|-----------------|--------------------------|\n",
    "| `learning_rate` | 1e-5 â€“ 1e-3 (escala logarÃ­tmica) |\n",
    "| `batch_size` | [16, 24, 32] |\n",
    "| `num_epochs` | 5 â€“ 12 |\n",
    "| `dropout` | 0.3 â€“ 0.6 (increments de 0.05) |\n",
    "\n",
    "### ğŸ”¬ TÃ¨cniques complementÃ ries per millorar lâ€™eficiÃ¨ncia\n",
    "\n",
    "- **Pruning automÃ tic:** interromp *trials* amb resultats no prometedors, estalviant temps computacional.  \n",
    "- **Early stopping:** atura lâ€™entrenament si no hi ha millora durant 5 Ã¨poques consecutives.  \n",
    "- **Scheduler dinÃ mic:** ajusta el *learning rate* automÃ ticament amb `ReduceLROnPlateau`.  \n",
    "\n",
    "Es duen a terme **20 trials**, que equivalen a unes 4â€“6 hores dâ€™entrenament en GPU.  \n",
    "El model amb la menor pÃ¨rdua de validaciÃ³ es desa automÃ ticament com el **millor resultat global**.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ˆ Resultats i mÃ¨triques\n",
    "\n",
    "DesprÃ©s de finalitzar lâ€™optimitzaciÃ³, el millor model Ã©s avaluat sobre el conjunt de **test**, generant un conjunt complet de resultats i informes:\n",
    "\n",
    "| Fitxer | DescripciÃ³ |\n",
    "|--------|-------------|\n",
    "| **`best_resnet_model_accXX.pth`** | Pesos del model final optimitzat |\n",
    "| **`resnet_model_config.json`** | ConfiguraciÃ³ dels hiperparÃ metres seleccionats |\n",
    "| **`confusion_matrix.png`** | Matriu de confusiÃ³ per classe |\n",
    "| **`optimization_report.json`** | Informe complet amb mÃ¨triques i resultats per classe |\n",
    "| **`optimization_history.png`** | EvoluciÃ³ de la pÃ¨rdua i lâ€™accuracy durant la optimitzaciÃ³ |\n",
    "| **`class_distribution.png`** | DistribuciÃ³ visual del dataset |\n",
    "\n",
    "Lâ€™informe inclou:\n",
    "- PrecisiÃ³ (*accuracy*), *recall*, *f1-score* i *support* per classe.  \n",
    "- AvaluaciÃ³ comparativa entre classes amb augmentaciÃ³ extra i classes estÃ ndard.  \n",
    "- IdentificaciÃ³ de les categories amb millor i pitjor rendiment.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e751d89-4ce3-4d2c-bc8b-bfed674a2ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ INICIANDO RESNET18 + OPTUNA - CLASSIFICACIÃ“ 6 CLASSES DE RESIDUS\n",
      "================================================================================\n",
      "ğŸ“‚ Carregant datasets amb 6 classes de residus...\n",
      "   ğŸ”„ Creant dataset train amb 6 classes de residus...\n",
      "   âœ… Dataset train creat: 9000 imatges\n",
      "   ğŸ“Š DistribuciÃ³ per classe: {'plastics': 3300, 'metalls': 1200, 'paper': 1800, 'vidre': 900, 'organic': 1200, 'textil': 600}\n",
      "   ğŸ”„ Creant dataset val amb 6 classes de residus...\n",
      "   âœ… Dataset val creat: 3000 imatges\n",
      "   ğŸ“Š DistribuciÃ³ per classe: {'plastics': 1100, 'metalls': 400, 'paper': 600, 'vidre': 300, 'organic': 400, 'textil': 200}\n",
      "   ğŸ”„ Creant dataset test amb 6 classes de residus...\n",
      "   âœ… Dataset test creat: 3000 imatges\n",
      "   ğŸ“Š DistribuciÃ³ per classe: {'plastics': 1100, 'metalls': 400, 'paper': 600, 'vidre': 300, 'organic': 400, 'textil': 200}\n",
      "ğŸ“Š Dataset: Train=9000, Val=3000, Test=3000 | 6 classes\n",
      "ğŸ·ï¸ Classes: ['plastics', 'metalls', 'paper', 'vidre', 'organic', 'textil']\n",
      "â­ AugmentaciÃ³ extra: {'textil', 'vidre'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 15:54:38,123] A new study created in memory with name: resnet18_waste_classification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š GrÃ fic de distribuciÃ³ guardat a: class_distribution.png\n",
      "âš–ï¸ Calculant pesos per equilibrar classes...\n",
      "   ğŸ“ˆ Pesos calculats per 9000 mostres d'entrenament\n",
      "ğŸ¯ Objectiu: Optimitzar ResNet18 per classificaciÃ³ de 6 classes de residus\n",
      "ğŸ’» Device: CUDA\n",
      "ğŸ”’ Transfer Learning: Congelades primeres capes de ResNet18\n",
      "âš–ï¸ EstratÃ¨gia: WeightedRandomSampler per equilibrar classes\n",
      "â­ AugmentaciÃ³ extra: vidre, textil\n",
      "â±ï¸ Temps estimat: 4-6 hores per 20 trials\n",
      "ğŸš€ Iniciant optimitzaciÃ³...\n",
      "\n",
      "ğŸ” Trial 1/20\n",
      "   ğŸ“Š ParÃ metres: lr=0.000048, bs=16, epochs=12, dropout=0.30\n",
      "   ğŸ§  ResNet18 inicialitzada amb 6 classes i dropout=0.3\n",
      "   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\n",
      "   ğŸ”“ Entrenables: layer3, layer4, fc\n",
      "   ğŸš€ Iniciant entrenament ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=0.7284(74.7%) | Val=0.6230(77.2%) â¬†ï¸\n",
      "   ğŸ† Â¡NOU RÃˆCORD GLOBAL! Val Loss: 0.622989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=0.4312(85.1%) | Val=0.4879(84.0%) â¬†ï¸\n",
      "   ğŸ† Â¡NOU RÃˆCORD GLOBAL! Val Loss: 0.487871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.3437(88.0%) | Val=0.4775(84.5%) â¬†ï¸\n",
      "   ğŸ† Â¡NOU RÃˆCORD GLOBAL! Val Loss: 0.477542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 4: Train=0.2908(89.9%) | Val=0.4816(84.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5: Train=0.2513(91.4%) | Val=0.4032(86.6%) â¬†ï¸\n",
      "   ğŸ† Â¡NOU RÃˆCORD GLOBAL! Val Loss: 0.403168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 6: Train=0.2352(91.9%) | Val=0.4183(86.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 7: Train=0.2189(92.9%) | Val=0.4069(87.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 8: Train=0.1922(93.6%) | Val=0.3777(87.9%) â¬†ï¸\n",
      "   ğŸ† Â¡NOU RÃˆCORD GLOBAL! Val Loss: 0.377721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 9: Train=0.1789(94.1%) | Val=0.4673(85.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 10: Train=0.1605(94.8%) | Val=0.4162(87.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 11: Train=0.1505(94.9%) | Val=0.3926(88.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 16:09:46,949] Trial 0 finished with value: 0.3581412802227436 and parameters: {'learning_rate': 4.765165349547268e-05, 'batch_size': 16, 'num_epochs': 12, 'dropout': 0.3}. Best is trial 0 with value: 0.3581412802227436.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 12: Train=0.1425(95.3%) | Val=0.3581(89.6%) â¬†ï¸\n",
      "   ğŸ† Â¡NOU RÃˆCORD GLOBAL! Val Loss: 0.358141\n",
      "   âœ… COMPLETAT - Millor Val Loss: 0.358141\n",
      "\n",
      "ğŸ” Trial 2/20\n",
      "   ğŸ“Š ParÃ metres: lr=0.000014, bs=16, epochs=11, dropout=0.60\n",
      "   ğŸ§  ResNet18 inicialitzada amb 6 classes i dropout=0.6\n",
      "   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\n",
      "   ğŸ”“ Entrenables: layer3, layer4, fc\n",
      "   ğŸš€ Iniciant entrenament ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=1.2761(51.7%) | Val=0.9626(63.5%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=0.7624(73.4%) | Val=0.7344(72.4%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.6085(78.9%) | Val=0.6236(77.4%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 4: Train=0.5404(81.3%) | Val=0.5223(81.6%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5: Train=0.4678(83.7%) | Val=0.5450(80.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 6: Train=0.4455(84.5%) | Val=0.5021(82.8%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 7: Train=0.3932(86.3%) | Val=0.4632(84.4%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 8: Train=0.3672(87.4%) | Val=0.4303(86.2%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 9: Train=0.3407(88.2%) | Val=0.4284(85.8%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 10: Train=0.3032(89.8%) | Val=0.4273(86.0%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 16:23:21,700] Trial 1 finished with value: 0.41858736919784084 and parameters: {'learning_rate': 1.3821746565361776e-05, 'batch_size': 16, 'num_epochs': 11, 'dropout': 0.6}. Best is trial 0 with value: 0.3581412802227436.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 11: Train=0.2855(90.6%) | Val=0.4186(86.4%) â¬†ï¸\n",
      "   âœ… COMPLETAT - Millor Val Loss: 0.418587\n",
      "\n",
      "ğŸ” Trial 3/20\n",
      "   ğŸ“Š ParÃ metres: lr=0.000037, bs=32, epochs=12, dropout=0.60\n",
      "   ğŸ§  ResNet18 inicialitzada amb 6 classes i dropout=0.6\n",
      "   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\n",
      "   ğŸ”“ Entrenables: layer3, layer4, fc\n",
      "   ğŸš€ Iniciant entrenament ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=1.0177(63.1%) | Val=0.7302(72.3%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=0.5474(81.0%) | Val=0.5893(78.1%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.4081(86.2%) | Val=0.5123(82.3%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 4: Train=0.3645(87.7%) | Val=0.4630(83.6%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5: Train=0.3198(89.2%) | Val=0.4360(85.2%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 6: Train=0.2677(91.5%) | Val=0.4278(86.4%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 7: Train=0.2294(92.1%) | Val=0.4300(86.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 8: Train=0.2172(92.7%) | Val=0.3898(87.8%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 9: Train=0.2009(93.1%) | Val=0.4192(87.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 10: Train=0.1850(93.8%) | Val=0.4202(88.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 11: Train=0.1698(94.4%) | Val=0.4273(87.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 16:38:16,922] Trial 2 finished with value: 0.38984864373552675 and parameters: {'learning_rate': 3.724584864173798e-05, 'batch_size': 32, 'num_epochs': 12, 'dropout': 0.6}. Best is trial 0 with value: 0.3581412802227436.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 12: Train=0.1627(94.6%) | Val=0.4163(89.3%)\n",
      "   âœ… COMPLETAT - Millor Val Loss: 0.389849\n",
      "\n",
      "ğŸ” Trial 4/20\n",
      "   ğŸ“Š ParÃ metres: lr=0.000031, bs=24, epochs=10, dropout=0.45\n",
      "   ğŸ§  ResNet18 inicialitzada amb 6 classes i dropout=0.45\n",
      "   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\n",
      "   ğŸ”“ Entrenables: layer3, layer4, fc\n",
      "   ğŸš€ Iniciant entrenament ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=0.9341(65.6%) | Val=0.7471(71.8%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=0.4897(83.3%) | Val=0.6246(77.5%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 16:42:08,706] Trial 3 pruned.                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.3912(86.4%) | Val=0.5738(79.8%) â¬†ï¸\n",
      "   âœ‚ï¸ Trial podat - no Ã©s prometedor\n",
      "\n",
      "ğŸ” Trial 5/20\n",
      "   ğŸ“Š ParÃ metres: lr=0.000011, bs=16, epochs=12, dropout=0.60\n",
      "   ğŸ§  ResNet18 inicialitzada amb 6 classes i dropout=0.6\n",
      "   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\n",
      "   ğŸ”“ Entrenables: layer3, layer4, fc\n",
      "   ğŸš€ Iniciant entrenament ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=1.3527(48.6%) | Val=1.1115(56.9%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=0.8308(70.5%) | Val=0.8150(69.4%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 16:45:51,727] Trial 4 pruned.                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.6650(76.3%) | Val=0.7443(72.6%) â¬†ï¸\n",
      "   âœ‚ï¸ Trial podat - no Ã©s prometedor\n",
      "\n",
      "ğŸ” Trial 6/20\n",
      "   ğŸ“Š ParÃ metres: lr=0.000298, bs=16, epochs=6, dropout=0.30\n",
      "   ğŸ§  ResNet18 inicialitzada amb 6 classes i dropout=0.3\n",
      "   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\n",
      "   ğŸ”“ Entrenables: layer3, layer4, fc\n",
      "   ğŸš€ Iniciant entrenament ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=0.7163(74.7%) | Val=0.8290(73.5%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=0.5247(82.0%) | Val=0.6441(78.2%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 16:49:33,178] Trial 5 pruned.                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.4248(85.4%) | Val=0.5814(81.9%) â¬†ï¸\n",
      "   âœ‚ï¸ Trial podat - no Ã©s prometedor\n",
      "\n",
      "ğŸ” Trial 7/20\n",
      "   ğŸ“Š ParÃ metres: lr=0.000143, bs=32, epochs=8, dropout=0.30\n",
      "   ğŸ§  ResNet18 inicialitzada amb 6 classes i dropout=0.3\n",
      "   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\n",
      "   ğŸ”“ Entrenables: layer3, layer4, fc\n",
      "   ğŸš€ Iniciant entrenament ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=0.6016(78.3%) | Val=0.5690(81.0%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=0.3649(87.5%) | Val=0.5415(81.5%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.2980(89.8%) | Val=0.4922(84.7%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 16:54:33,297] Trial 6 pruned.                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 4: Train=0.2595(91.2%) | Val=0.5182(82.6%)\n",
      "   âœ‚ï¸ Trial podat - no Ã©s prometedor\n",
      "\n",
      "ğŸ” Trial 8/20\n",
      "   ğŸ“Š ParÃ metres: lr=0.000628, bs=24, epochs=9, dropout=0.40\n",
      "   ğŸ§  ResNet18 inicialitzada amb 6 classes i dropout=0.4\n",
      "   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\n",
      "   ğŸ”“ Entrenables: layer3, layer4, fc\n",
      "   ğŸš€ Iniciant entrenament ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=0.8085(71.8%) | Val=1.5407(59.7%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=0.5701(79.8%) | Val=1.0264(71.0%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 16:58:21,928] Trial 7 pruned.                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.4921(82.8%) | Val=0.7203(77.7%) â¬†ï¸\n",
      "   âœ‚ï¸ Trial podat - no Ã©s prometedor\n",
      "\n",
      "ğŸ” Trial 9/20\n",
      "   ğŸ“Š ParÃ metres: lr=0.000070, bs=16, epochs=5, dropout=0.45\n",
      "   ğŸ§  ResNet18 inicialitzada amb 6 classes i dropout=0.45\n",
      "   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\n",
      "   ğŸ”“ Entrenables: layer3, layer4, fc\n",
      "   ğŸš€ Iniciant entrenament ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=0.7141(74.6%) | Val=0.6604(77.3%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=0.4385(84.5%) | Val=0.5561(81.7%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 17:02:04,221] Trial 8 pruned.                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.3667(87.2%) | Val=0.5237(83.4%) â¬†ï¸\n",
      "   âœ‚ï¸ Trial podat - no Ã©s prometedor\n",
      "\n",
      "ğŸ” Trial 10/20\n",
      "   ğŸ“Š ParÃ metres: lr=0.000150, bs=16, epochs=8, dropout=0.35\n",
      "   ğŸ§  ResNet18 inicialitzada amb 6 classes i dropout=0.35\n",
      "   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\n",
      "   ğŸ”“ Entrenables: layer3, layer4, fc\n",
      "   ğŸš€ Iniciant entrenament ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=0.6552(77.1%) | Val=0.7335(75.8%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=0.4433(84.8%) | Val=0.7158(76.9%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 17:05:52,216] Trial 9 pruned.                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.3741(87.0%) | Val=0.5621(82.3%) â¬†ï¸\n",
      "   âœ‚ï¸ Trial podat - no Ã©s prometedor\n",
      "\n",
      "ğŸ” Trial 11/20\n",
      "   ğŸ“Š ParÃ metres: lr=0.000997, bs=24, epochs=10, dropout=0.50\n",
      "   ğŸ§  ResNet18 inicialitzada amb 6 classes i dropout=0.5\n",
      "   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\n",
      "   ğŸ”“ Entrenables: layer3, layer4, fc\n",
      "   ğŸš€ Iniciant entrenament ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=0.9251(68.1%) | Val=0.9380(69.9%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=0.6806(76.2%) | Val=1.4946(56.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 17:09:37,818] Trial 10 pruned.                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.6262(78.9%) | Val=0.9283(72.7%) â¬†ï¸\n",
      "   âœ‚ï¸ Trial podat - no Ã©s prometedor\n",
      "\n",
      "ğŸ” Trial 12/20\n",
      "   ğŸ“Š ParÃ metres: lr=0.000044, bs=32, epochs=12, dropout=0.55\n",
      "   ğŸ§  ResNet18 inicialitzada amb 6 classes i dropout=0.55\n",
      "   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\n",
      "   ğŸ”“ Entrenables: layer3, layer4, fc\n",
      "   ğŸš€ Iniciant entrenament ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=0.9021(67.2%) | Val=0.6610(76.2%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=0.4787(83.5%) | Val=0.5204(82.1%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.3657(87.2%) | Val=0.4646(84.7%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 4: Train=0.3194(88.9%) | Val=0.4419(85.4%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 17:15:49,811] Trial 11 pruned.                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5: Train=0.2728(90.6%) | Val=0.4804(84.0%)\n",
      "   âœ‚ï¸ Trial podat - no Ã©s prometedor\n",
      "\n",
      "ğŸ” Trial 13/20\n",
      "   ğŸ“Š ParÃ metres: lr=0.000037, bs=32, epochs=12, dropout=0.50\n",
      "   ğŸ§  ResNet18 inicialitzada amb 6 classes i dropout=0.5\n",
      "   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\n",
      "   ğŸ”“ Entrenables: layer3, layer4, fc\n",
      "   ğŸš€ Iniciant entrenament ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=0.9284(66.0%) | Val=0.6874(75.7%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=0.5064(82.3%) | Val=0.6073(78.1%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.3870(86.5%) | Val=0.5095(82.9%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 4: Train=0.3162(89.3%) | Val=0.4564(84.0%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 17:22:09,962] Trial 12 pruned.                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5: Train=0.2728(90.8%) | Val=0.4640(84.9%)\n",
      "   âœ‚ï¸ Trial podat - no Ã©s prometedor\n",
      "\n",
      "ğŸ” Trial 14/20\n",
      "   ğŸ“Š ParÃ metres: lr=0.000027, bs=32, epochs=11, dropout=0.40\n",
      "   ğŸ§  ResNet18 inicialitzada amb 6 classes i dropout=0.4\n",
      "   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\n",
      "   ğŸ”“ Entrenables: layer3, layer4, fc\n",
      "   ğŸš€ Iniciant entrenament ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=0.9978(63.9%) | Val=0.7869(71.0%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=0.5149(82.1%) | Val=0.6033(79.1%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.3983(86.2%) | Val=0.5121(81.9%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 17:27:05,824] Trial 13 pruned.                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 4: Train=0.3479(87.9%) | Val=0.4939(82.8%) â¬†ï¸\n",
      "   âœ‚ï¸ Trial podat - no Ã©s prometedor\n",
      "\n",
      "ğŸ” Trial 15/20\n",
      "   ğŸ“Š ParÃ metres: lr=0.000086, bs=32, epochs=10, dropout=0.35\n",
      "   ğŸ§  ResNet18 inicialitzada amb 6 classes i dropout=0.35\n",
      "   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\n",
      "   ğŸ”“ Entrenables: layer3, layer4, fc\n",
      "   ğŸš€ Iniciant entrenament ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=0.6724(76.0%) | Val=0.5948(79.2%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=0.3736(87.2%) | Val=0.6295(78.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.2954(90.0%) | Val=0.4655(84.9%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 4: Train=0.2509(91.5%) | Val=0.4197(86.6%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5: Train=0.2057(93.3%) | Val=0.4355(86.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 6: Train=0.1982(93.3%) | Val=0.3886(87.7%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 7: Train=0.1687(94.2%) | Val=0.4711(86.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 8: Train=0.1593(94.8%) | Val=0.3869(88.6%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 9: Train=0.1519(95.2%) | Val=0.3787(88.7%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 17:39:43,025] Trial 14 finished with value: 0.3786750911794444 and parameters: {'learning_rate': 8.573019738546585e-05, 'batch_size': 32, 'num_epochs': 10, 'dropout': 0.35}. Best is trial 0 with value: 0.3581412802227436.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 10: Train=0.1355(95.5%) | Val=0.3980(88.5%)\n",
      "   âœ… COMPLETAT - Millor Val Loss: 0.378675\n",
      "\n",
      "ğŸ” Trial 16/20\n",
      "   ğŸ“Š ParÃ metres: lr=0.000080, bs=16, epochs=10, dropout=0.35\n",
      "   ğŸ§  ResNet18 inicialitzada amb 6 classes i dropout=0.35\n",
      "   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\n",
      "   ğŸ”“ Entrenables: layer3, layer4, fc\n",
      "   ğŸš€ Iniciant entrenament ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=0.6743(75.8%) | Val=0.7794(73.2%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=0.4299(85.4%) | Val=0.4667(84.2%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.3349(88.5%) | Val=0.5013(83.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 4: Train=0.2974(90.0%) | Val=0.4542(86.2%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 17:45:58,382] Trial 15 pruned.                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5: Train=0.2679(90.6%) | Val=0.4583(86.1%)\n",
      "   âœ‚ï¸ Trial podat - no Ã©s prometedor\n",
      "\n",
      "ğŸ” Trial 17/20\n",
      "   ğŸ“Š ParÃ metres: lr=0.000249, bs=32, epochs=7, dropout=0.35\n",
      "   ğŸ§  ResNet18 inicialitzada amb 6 classes i dropout=0.35\n",
      "   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\n",
      "   ğŸ”“ Entrenables: layer3, layer4, fc\n",
      "   ğŸš€ Iniciant entrenament ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=0.6208(78.1%) | Val=0.6618(77.9%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=0.3974(86.5%) | Val=0.8001(76.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 17:49:47,523] Trial 16 pruned.                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.3274(88.7%) | Val=0.5725(81.6%) â¬†ï¸\n",
      "   âœ‚ï¸ Trial podat - no Ã©s prometedor\n",
      "\n",
      "ğŸ” Trial 18/20\n",
      "   ğŸ“Š ParÃ metres: lr=0.000061, bs=32, epochs=9, dropout=0.30\n",
      "   ğŸ§  ResNet18 inicialitzada amb 6 classes i dropout=0.3\n",
      "   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\n",
      "   ğŸ”“ Entrenables: layer3, layer4, fc\n",
      "   ğŸš€ Iniciant entrenament ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=0.7266(74.2%) | Val=0.6435(76.4%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=0.3913(86.5%) | Val=0.4926(82.5%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.3000(89.7%) | Val=0.4771(84.7%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 17:54:48,042] Trial 17 pruned.                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 4: Train=0.2433(92.0%) | Val=0.5175(83.2%)\n",
      "   âœ‚ï¸ Trial podat - no Ã©s prometedor\n",
      "\n",
      "ğŸ” Trial 19/20\n",
      "   ğŸ“Š ParÃ metres: lr=0.000019, bs=16, epochs=11, dropout=0.40\n",
      "   ğŸ§  ResNet18 inicialitzada amb 6 classes i dropout=0.4\n",
      "   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\n",
      "   ğŸ”“ Entrenables: layer3, layer4, fc\n",
      "   ğŸš€ Iniciant entrenament ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=1.0280(62.7%) | Val=0.8706(66.8%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=0.5800(79.8%) | Val=0.6036(78.2%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 17:58:33,309] Trial 18 pruned.                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.4766(83.5%) | Val=0.5386(80.8%) â¬†ï¸\n",
      "   âœ‚ï¸ Trial podat - no Ã©s prometedor\n",
      "\n",
      "ğŸ” Trial 20/20\n",
      "   ğŸ“Š ParÃ metres: lr=0.000130, bs=24, epochs=11, dropout=0.35\n",
      "   ğŸ§  ResNet18 inicialitzada amb 6 classes i dropout=0.35\n",
      "   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\n",
      "   ğŸ”“ Entrenables: layer3, layer4, fc\n",
      "   ğŸš€ Iniciant entrenament ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train=0.6147(78.6%) | Val=0.6313(77.3%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train=0.3884(86.5%) | Val=0.5967(80.9%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train=0.3116(89.2%) | Val=0.4767(84.9%) â¬†ï¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 18:03:32,474] Trial 19 pruned.                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 4: Train=0.2717(90.9%) | Val=0.4936(84.8%)\n",
      "   âœ‚ï¸ Trial podat - no Ã©s prometedor\n",
      "\n",
      "================================================================================\n",
      "ğŸ‰ OPTIMITZACIÃ“ RESNET18 COMPLETADA - 6 CLASSES DE RESIDUS\n",
      "================================================================================\n",
      "ğŸ† MILLOR RESULTAT:\n",
      "   ğŸ“Š Validation Loss: 0.358141\n",
      "   âš™ï¸ ParÃ metres: {'learning_rate': 4.765165349547268e-05, 'batch_size': 16, 'num_epochs': 12, 'dropout': 0.3}\n",
      "   ğŸ”¢ Trial nÃºmero: 0\n",
      "\n",
      "ğŸ“ˆ Resum de trials:\n",
      "   âœ… Trials completats: 20\n",
      "   âœ‚ï¸ Trials podats: 16\n",
      "   âŒ Trials fallits: 0\n",
      "\n",
      "ğŸ§ª AVALUACIÃ“ EN TEST SET:\n",
      "------------------------------------------------------------\n",
      "   ğŸ§  ResNet18 inicialitzada amb 6 classes i dropout=0.3\n",
      "   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\n",
      "   ğŸ”“ Entrenables: layer3, layer4, fc\n",
      "ğŸ” Avaluant model en dataset de test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AvaluaciÃ³: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Test Loss: 0.315282\n",
      "ğŸ¯ Test Accuracy: 90.13%\n",
      "ğŸ“Š Matriu de confusiÃ³ guardada a: confusion_matrix.png\n",
      "ğŸ“„ Informe complet guardat a: optimization_report.json\n",
      "ğŸ“ˆ GrÃ fic d'optimitzaciÃ³ guardat a: optimization_history.png\n",
      "Files generated:\n",
      "   best_resnet_model_acc90.1.pth - Optimized ResNet18 model\n",
      "   resnet_model_config.json - Complete model configuration\n",
      "   confusion_matrix.png - Confusion matrix\n",
      "   optimization_report.json - Detailed optimization report\n",
      "   optimization_history.png - Optimization history\n",
      "   class_distribution.png - Class distribution\n",
      "\n",
      "PERFORMANCE ANALYSIS:\n",
      "------------------------------------------------------------\n",
      "Class       Precision     Recall   F1-Score    Support\n",
      "------------------------------------------------------------\n",
      "plastics        0.930      0.905      0.918       1100\n",
      "metalls         0.835      0.948      0.888        400\n",
      "paper           0.881      0.913      0.897        600\n",
      "vidre *         0.901      0.823      0.861        300\n",
      "organic         0.949      0.892      0.920        400\n",
      "textil *        0.872      0.885      0.878        200\n",
      "------------------------------------------------------------\n",
      "Macro Avg       0.895      0.895      0.894\n",
      "Weighted Avg      0.903      0.901      0.901\n",
      "\n",
      "Best performing class: organic (F1: 0.920)\n",
      "Needs improvement: vidre (F1: 0.861)\n",
      "\n",
      "EFFECT OF EXTRA AUGMENTATION:\n",
      "   Classes with extra augmentation (vidre, textil): F1 avg = 0.870\n",
      "   Normal classes: F1 avg = 0.906\n",
      "   Extra augmentation did not significantly improve performance\n",
      "\n",
      "HOW TO USE THE TRAINED MODEL:\n",
      "------------------------------------------------------------\n",
      "```python\n",
      "import torch\n",
      "from torchvision import transforms\n",
      "import json\n",
      "\n",
      "# Load configuration\n",
      "with open('resnet_model_config.json', 'r') as f:\n",
      "    config = json.load(f)\n",
      "\n",
      "# Create model\n",
      "model = ResNetWasteClassifier(\n",
      "    num_classes=6,\n",
      "    dropout=0.3\n",
      ")\n",
      "\n",
      "# Load weights\n",
      "model.load_state_dict(torch.load('best_resnet_model_acc90.1.pth'))\n",
      "model.eval()\n",
      "\n",
      "# Preprocess image\n",
      "transform = transforms.Compose([\n",
      "    transforms.Resize((224, 224)),\n",
      "    transforms.ToTensor(),\n",
      "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "])\n",
      "```\n",
      "\n",
      "PROCESS COMPLETED SUCCESSFULLY!\n",
      "\n",
      "================================================================================\n",
      "WASTE CLASSIFICATION SYSTEM INFORMATION\n",
      "================================================================================\n",
      "Waste classes (6):\n",
      "   0: plastics\n",
      "   1: metalls\n",
      "   2: paper\n",
      "   3: vidre *\n",
      "   4: organic\n",
      "   5: textil *\n",
      "\n",
      "Model architecture:\n",
      "   Base: ResNet18 (pretrained on ImageNet)\n",
      "   Frozen: conv1, bn1, layer1, layer2\n",
      "   Trainable: layer3, layer4, fc\n",
      "   Output classes: 6\n",
      "\n",
      "Training configuration:\n",
      "   Dataset structure: Flat by classes\n",
      "   Balancing: WeightedRandomSampler\n",
      "   Augmentation: Dynamic + extra for vidre/textil\n",
      "   Split: 60% train / 20% val / 20% test\n",
      "   Optimization: Optuna TPE + MedianPruner\n",
      "   Scheduler: ReduceLROnPlateau\n",
      "   Early Stopping: Patience 5 epochs\n",
      "\n",
      "END OF RESNET18 OPTIMIZATION PROCESS\n",
      "Model ready to classify 6 types of waste!\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "# Dataset Class amb AugmentaciÃ³ EspecÃ­fica per Classes\n",
    "class WasteDataset6Classes(Dataset):\n",
    "    def __init__(self, root_dir, split, transform=None, val_transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.val_transform = val_transform\n",
    "        self.split = split\n",
    "        \n",
    "        # 6 classes de residus\n",
    "        self.classes = ['plastics', 'metalls', 'paper', 'vidre', 'organic', 'textil']\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        \n",
    "        # Classes que necessiten augmentaciÃ³ extra\n",
    "        self.extra_augmentation_classes = {'vidre', 'textil'}\n",
    "        \n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        print(f\"   ğŸ”„ Creant dataset {split} amb 6 classes de residus...\")\n",
    "        \n",
    "        # Carregar imatges per cada classe\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            if not os.path.exists(class_dir):\n",
    "                print(f\"   âš ï¸ AdvertÃ¨ncia: No es troba la carpeta {class_dir}\")\n",
    "                continue\n",
    "                \n",
    "            # Obtenir totes les imatges de la classe\n",
    "            image_names = []\n",
    "            for file in os.listdir(class_dir):\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    image_names.append(file)\n",
    "            \n",
    "            # Barrejar per splits consistents\n",
    "            random.seed(42)\n",
    "            random.shuffle(image_names)\n",
    "            \n",
    "            # Dividir segons split (60/20/20)\n",
    "            total_images = len(image_names)\n",
    "            train_end = int(0.6 * total_images)\n",
    "            val_end = int(0.8 * total_images)\n",
    "            \n",
    "            if split == 'train':\n",
    "                selected_images = image_names[:train_end]\n",
    "            elif split == 'val':\n",
    "                selected_images = image_names[train_end:val_end]\n",
    "            else:  # test\n",
    "                selected_images = image_names[val_end:]\n",
    "            \n",
    "            # Afegir al dataset\n",
    "            for image_name in selected_images:\n",
    "                full_path = os.path.join(class_dir, image_name)\n",
    "                self.image_paths.append(full_path)\n",
    "                self.labels.append(self.class_to_idx[class_name])\n",
    "        \n",
    "        # EstadÃ­stiques del dataset\n",
    "        label_counts = Counter(self.labels)\n",
    "        class_distribution = {self.classes[i]: label_counts[i] for i in range(len(self.classes))}\n",
    "        \n",
    "        print(f\"   âœ… Dataset {split} creat: {len(self.image_paths)} imatges\")\n",
    "        print(f\"   ğŸ“Š DistribuciÃ³ per classe: {class_distribution}\")\n",
    "        \n",
    "        # Crear transformacions d'augmentaciÃ³ extra per vidre i textil\n",
    "        if split == 'train':\n",
    "            self.extra_transform = transforms.Compose([\n",
    "                transforms.Resize((256, 256)),\n",
    "                transforms.RandomCrop((224, 224)),\n",
    "                transforms.RandomHorizontalFlip(p=0.6),\n",
    "                transforms.RandomVerticalFlip(p=0.3),\n",
    "                transforms.RandomRotation(degrees=45),\n",
    "                transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
    "                transforms.RandomAffine(degrees=15, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "                transforms.RandomGrayscale(p=0.1),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        label = self.labels[index]\n",
    "        class_name = self.classes[label]\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error carregant {image_path}: {e}\")\n",
    "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        \n",
    "        # Aplicar transformacions segons el split i la classe\n",
    "        if self.split == 'train' and self.transform:\n",
    "            # Si Ã©s classe vidre o textil, aplicar augmentaciÃ³ extra\n",
    "            if class_name in self.extra_augmentation_classes:\n",
    "                image = self.extra_transform(image)\n",
    "            else:\n",
    "                image = self.transform(image)\n",
    "        elif self.val_transform and self.split in ['val', 'test']:\n",
    "            image = self.val_transform(image)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def get_class_weights(self):\n",
    "        \"\"\"Calcula els pesos per WeightedRandomSampler\"\"\"\n",
    "        label_counts = Counter(self.labels)\n",
    "        total_samples = len(self.labels)\n",
    "        \n",
    "        # Calcular pesos inversament proporcionals a la freqÃ¼Ã¨ncia\n",
    "        class_weights = []\n",
    "        for i in range(len(self.classes)):\n",
    "            count = label_counts[i] if i in label_counts else 1\n",
    "            weight = total_samples / (len(self.classes) * count)\n",
    "            class_weights.append(weight)\n",
    "        \n",
    "        # Crear pesos per cada mostra\n",
    "        sample_weights = [class_weights[label] for label in self.labels]\n",
    "        \n",
    "        return torch.DoubleTensor(sample_weights)\n",
    "\n",
    "# Model ResNet18 amb Transfer Learning\n",
    "class ResNetWasteClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=6, dropout=0.5):\n",
    "        super(ResNetWasteClassifier, self).__init__()\n",
    "        \n",
    "        # Carregar ResNet18 preentrenada (fix for deprecation warning)\n",
    "        try:\n",
    "            # Try new weights parameter first\n",
    "            self.resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        except:\n",
    "            # Fall back to pretrained parameter\n",
    "            self.resnet = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # Congelar primeres capes (conv1, layer1, layer2)\n",
    "        for param in self.resnet.conv1.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.resnet.bn1.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.resnet.layer1.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.resnet.layer2.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Deixar entrenables layer3, layer4\n",
    "        for param in self.resnet.layer3.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.resnet.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        # Modificar la fully connected layer\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(num_features, num_classes)\n",
    "        )\n",
    "        \n",
    "        print(f\"   ğŸ§  ResNet18 inicialitzada amb {num_classes} classes i dropout={dropout}\")\n",
    "        print(f\"   ğŸ”’ Congelades: conv1, bn1, layer1, layer2\")\n",
    "        print(f\"   ğŸ”“ Entrenables: layer3, layer4, fc\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device, class_names):\n",
    "    \"\"\"Avalua el model i retorna mÃ¨triques detallades\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    print(\"ğŸ” Avaluant model en dataset de test...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"AvaluaciÃ³\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_loss = total_loss / len(test_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return {\n",
    "        'test_loss': test_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': all_preds,\n",
    "        'true_labels': all_labels,\n",
    "        'classification_report': classification_report(all_labels, all_preds, \n",
    "                                                     target_names=class_names, \n",
    "                                                     output_dict=True, zero_division=0)\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, save_path='confusion_matrix.png'):\n",
    "    \"\"\"Genera i guarda la matriu de confusiÃ³\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Matriu de ConfusiÃ³ - ResNet18 Optimitzat', fontsize=16, pad=20)\n",
    "    plt.ylabel('Etiquetes Reals', fontsize=12)\n",
    "    plt.xlabel('Prediccions', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"ğŸ“Š Matriu de confusiÃ³ guardada a: {save_path}\")\n",
    "\n",
    "def generate_report(study, best_metrics, class_names, save_path='optimization_report.json'):\n",
    "    \"\"\"Genera un informe complet de l'optimitzaciÃ³\"\"\"\n",
    "    report = {\n",
    "        'optimization_info': {\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'project': 'ClassificaciÃ³ de Residus - ResNet18 + Optuna',\n",
    "            'model_architecture': 'ResNet18 (Transfer Learning)',\n",
    "            'frozen_layers': ['conv1', 'bn1', 'layer1', 'layer2'],\n",
    "            'trainable_layers': ['layer3', 'layer4', 'fc'],\n",
    "            'dataset_info': {\n",
    "                'classes': class_names,\n",
    "                'total_classes': len(class_names),\n",
    "                'data_split': '60/20/20 (train/val/test)',\n",
    "                'extra_augmentation': ['vidre', 'textil']\n",
    "            },\n",
    "            'n_trials': len(study.trials),\n",
    "            'best_trial_number': study.best_trial.number,\n",
    "            'optimization_direction': 'minimize_validation_loss'\n",
    "        },\n",
    "        'best_hyperparameters': study.best_trial.params,\n",
    "        'best_validation_loss': study.best_trial.value,\n",
    "        'test_metrics': {\n",
    "            'test_loss': best_metrics['test_loss'],\n",
    "            'test_accuracy': best_metrics['accuracy']\n",
    "        },\n",
    "        'detailed_classification_report': best_metrics['classification_report'],\n",
    "        'trial_history': [\n",
    "            {\n",
    "                'trial': t.number,\n",
    "                'params': t.params,\n",
    "                'value': t.value,\n",
    "                'state': str(t.state)\n",
    "            } for t in study.trials if t.value is not None\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(report, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"ğŸ“„ Informe complet guardat a: {save_path}\")\n",
    "    return report\n",
    "\n",
    "def plot_optimization_history(study, save_path='optimization_history.png'):\n",
    "    \"\"\"Genera grÃ fic de la histÃ²ria d'optimitzaciÃ³\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # HistÃ²ria de valors\n",
    "    trial_numbers = [t.number for t in study.trials if t.value is not None]\n",
    "    values = [t.value for t in study.trials if t.value is not None]\n",
    "    \n",
    "    ax1.plot(trial_numbers, values, 'b-o', markersize=6, linewidth=2)\n",
    "    ax1.axhline(y=study.best_value, color='r', linestyle='--', linewidth=2, \n",
    "                label=f'Millor: {study.best_value:.4f}')\n",
    "    ax1.set_xlabel('Trial Number')\n",
    "    ax1.set_ylabel('Validation Loss')\n",
    "    ax1.set_title('HistÃ²ria d\\'OptimitzaciÃ³ ResNet18')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # DistribuciÃ³ de valors\n",
    "    if len(values) > 0:\n",
    "        ax2.hist(values, bins=min(15, len(values)), alpha=0.7, color='lightblue', \n",
    "                edgecolor='darkblue', linewidth=1)\n",
    "        ax2.axvline(x=study.best_value, color='r', linestyle='--', linewidth=2, \n",
    "                   label=f'Millor: {study.best_value:.4f}')\n",
    "    ax2.set_xlabel('Validation Loss')\n",
    "    ax2.set_ylabel('FreqÃ¼Ã¨ncia')\n",
    "    ax2.set_title('DistribuciÃ³ de Resultats')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"ğŸ“ˆ GrÃ fic d'optimitzaciÃ³ guardat a: {save_path}\")\n",
    "\n",
    "def plot_class_distribution(train_dataset, save_path='class_distribution.png'):\n",
    "    \"\"\"Genera grÃ fic de distribuciÃ³ de classes\"\"\"\n",
    "    label_counts = Counter(train_dataset.labels)\n",
    "    class_names = train_dataset.classes\n",
    "    counts = [label_counts[i] for i in range(len(class_names))]\n",
    "    \n",
    "    # Colors personalitzats per cada classe\n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57', '#FF9FF3']\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bars = plt.bar(class_names, counts, color=colors[:len(class_names)])\n",
    "    \n",
    "    # Afegir valors sobre les barres\n",
    "    for bar, count in zip(bars, counts):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, height + max(counts)*0.01, \n",
    "                str(count), ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "    \n",
    "    plt.title('DistribuciÃ³ de Classes en Dataset d\\'Entrenament (6 Classes)', fontsize=16, pad=20)\n",
    "    plt.xlabel('Classes de Residus', fontsize=12)\n",
    "    plt.ylabel('Nombre d\\'Imatges', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Remove special character issue with standard text\n",
    "    plt.figtext(0.02, 0.02, \n",
    "                \"Extra augmentation applied to: vidre, textil\", \n",
    "                fontsize=10, style='italic', color='darkred')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"ğŸ“Š GrÃ fic de distribuciÃ³ guardat a: {save_path}\")\n",
    "\n",
    "# ConfiguraciÃ³ Principal\n",
    "print(\"ğŸš€ INICIANDO RESNET18 + OPTUNA - CLASSIFICACIÃ“ 6 CLASSES DE RESIDUS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Transformacions d'augmentaciÃ³ per entrenament\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=20),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Transformacions sense augmentaciÃ³ per validaciÃ³ i test\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Inicialitzar datasets\n",
    "print(\"ğŸ“‚ Carregant datasets amb 6 classes de residus...\")\n",
    "dataset_path = 'images_6classes'\n",
    "\n",
    "train_dataset = WasteDataset6Classes(dataset_path, 'train', \n",
    "                                    transform=train_transform, \n",
    "                                    val_transform=val_test_transform)\n",
    "val_dataset = WasteDataset6Classes(dataset_path, 'val', \n",
    "                                  val_transform=val_test_transform)\n",
    "test_dataset = WasteDataset6Classes(dataset_path, 'test', \n",
    "                                   val_transform=val_test_transform)\n",
    "\n",
    "print(f\"ğŸ“Š Dataset: Train={len(train_dataset)}, Val={len(val_dataset)}, Test={len(test_dataset)} | {len(train_dataset.classes)} classes\")\n",
    "print(f\"ğŸ·ï¸ Classes: {train_dataset.classes}\")\n",
    "print(f\"â­ AugmentaciÃ³ extra: {train_dataset.extra_augmentation_classes}\")\n",
    "\n",
    "# Generar grÃ fic de distribuciÃ³\n",
    "plot_class_distribution(train_dataset)\n",
    "\n",
    "# Calcular pesos per WeightedRandomSampler\n",
    "print(\"âš–ï¸ Calculant pesos per equilibrar classes...\")\n",
    "sample_weights = train_dataset.get_class_weights()\n",
    "print(f\"   ğŸ“ˆ Pesos calculats per {len(sample_weights)} mostres d'entrenament\")\n",
    "\n",
    "# Variables globals per tracking\n",
    "best_global_loss = float('inf')\n",
    "best_model_state = None\n",
    "trial_count = 0\n",
    "\n",
    "def objective(trial):\n",
    "    global best_global_loss, best_model_state, trial_count\n",
    "    trial_count += 1\n",
    "    \n",
    "    # HiperparÃ metres a optimitzar\n",
    "    lr = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 24, 32])\n",
    "    epochs = trial.suggest_int('num_epochs', 5, 12)\n",
    "    dropout = trial.suggest_float('dropout', 0.3, 0.6, step=0.05)\n",
    "    \n",
    "    print(f\"\\nğŸ” Trial {trial_count}/20\")\n",
    "    print(f\"   ğŸ“Š ParÃ metres: lr={lr:.6f}, bs={batch_size}, epochs={epochs}, dropout={dropout:.2f}\")\n",
    "    \n",
    "    # Crear DataLoaders amb WeightedRandomSampler\n",
    "    weighted_sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        sampler=weighted_sampler,\n",
    "        num_workers=0, \n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=0, \n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    # Model setup\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = ResNetWasteClassifier(num_classes=len(train_dataset.classes), dropout=dropout).to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    \n",
    "    # Learning rate scheduler - FIXED: removed verbose parameter\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    patience = 5\n",
    "    \n",
    "    print(f\"   ğŸš€ Iniciant entrenament ResNet18...\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        train_bar = tqdm(train_loader, desc=f\"   Epoch {epoch+1}/{epochs} [Train]\", leave=False)\n",
    "        for images, labels in train_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Actualitzar barra de progrÃ©s\n",
    "            current_train_loss = train_loss / (train_bar.n + 1)\n",
    "            current_train_acc = 100. * train_correct / train_total\n",
    "            train_bar.set_postfix({'Loss': f'{current_train_loss:.4f}', 'Acc': f'{current_train_acc:.1f}%'})\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_accuracy = 100. * train_correct / train_total\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(val_loader, desc=f\"   Epoch {epoch+1}/{epochs} [Val]  \", leave=False)\n",
    "            for images, labels in val_bar:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # Actualitzar barra de progrÃ©s\n",
    "                current_val_loss = val_loss / (val_bar.n + 1)\n",
    "                current_val_acc = 100. * val_correct / val_total\n",
    "                val_bar.set_postfix({'Loss': f'{current_val_loss:.4f}', 'Acc': f'{current_val_acc:.1f}%'})\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100. * val_correct / val_total\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Mostrar resultats de l'epoch\n",
    "        improvement_indicator = \"\"\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            improvement_indicator = \" â¬†ï¸\"\n",
    "        \n",
    "        print(f\"   Epoch {epoch+1}: Train={avg_train_loss:.4f}({train_accuracy:.1f}%) | Val={avg_val_loss:.4f}({val_accuracy:.1f}%){improvement_indicator}\")\n",
    "        \n",
    "        # Report intermediate result per pruning\n",
    "        trial.report(avg_val_loss, epoch)\n",
    "        \n",
    "        # Prune si no Ã©s prometedor\n",
    "        if trial.should_prune():\n",
    "            print(f\"   âœ‚ï¸ Trial podat - no Ã©s prometedor\")\n",
    "            raise optuna.TrialPruned()\n",
    "        \n",
    "        # Update best validation loss\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # Si Ã©s el millor model global, guardar-lo\n",
    "            if avg_val_loss < best_global_loss:\n",
    "                best_global_loss = avg_val_loss\n",
    "                best_model_state = model.state_dict().copy()\n",
    "                torch.save(best_model_state, 'best_resnet_temp.pth')\n",
    "                print(f\"   ğŸ† Â¡NOU RÃˆCORD GLOBAL! Val Loss: {avg_val_loss:.6f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"   â° Early stopping (sense millora per {patience} epochs)\")\n",
    "            break\n",
    "    \n",
    "    print(f\"   âœ… COMPLETAT - Millor Val Loss: {best_val_loss:.6f}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    del model, train_loader, val_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return best_val_loss\n",
    "\n",
    "# Main execution with proper error handling\n",
    "if __name__ == \"__main__\":\n",
    "    # Crear estudi d'Optuna\n",
    "    print(f\"ğŸ¯ Objectiu: Optimitzar ResNet18 per classificaciÃ³ de 6 classes de residus\")\n",
    "    print(f\"ğŸ’» Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "    print(f\"ğŸ”’ Transfer Learning: Congelades primeres capes de ResNet18\")\n",
    "    print(f\"âš–ï¸ EstratÃ¨gia: WeightedRandomSampler per equilibrar classes\")\n",
    "    print(f\"â­ AugmentaciÃ³ extra: vidre, textil\")\n",
    "    print(f\"â±ï¸ Temps estimat: 4-6 hores per 20 trials\")\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        direction='minimize',\n",
    "        study_name='resnet18_waste_classification',\n",
    "        sampler=optuna.samplers.TPESampler(n_startup_trials=5),\n",
    "        pruner=optuna.pruners.MedianPruner(n_startup_trials=3, n_warmup_steps=2)\n",
    "    )\n",
    "\n",
    "    # Executar optimitzaciÃ³\n",
    "    print(\"ğŸš€ Iniciant optimitzaciÃ³...\")\n",
    "    try:\n",
    "        study.optimize(objective, n_trials=20, timeout=21600)  # 20 trials, 6h max\n",
    "        optimization_completed = True\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"â¸ï¸ Interromput per usuari\")\n",
    "        optimization_completed = True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error durant optimitzaciÃ³: {e}\")\n",
    "        optimization_completed = False\n",
    "\n",
    "    # Resultats finals - FIXED: proper error handling\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ‰ OPTIMITZACIÃ“ RESNET18 COMPLETADA - 6 CLASSES DE RESIDUS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Check if we have any successful trials\n",
    "    completed_trials = [t for t in study.trials if t.value is not None]\n",
    "    \n",
    "    if len(completed_trials) > 0:\n",
    "        best_trial = min(completed_trials, key=lambda t: t.value)\n",
    "        print(f\"ğŸ† MILLOR RESULTAT:\")\n",
    "        print(f\"   ğŸ“Š Validation Loss: {best_trial.value:.6f}\")\n",
    "        print(f\"   âš™ï¸ ParÃ metres: {best_trial.params}\")\n",
    "        print(f\"   ğŸ”¢ Trial nÃºmero: {best_trial.number}\")\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ Resum de trials:\")\n",
    "        print(f\"   âœ… Trials completats: {len(completed_trials)}\")\n",
    "        print(f\"   âœ‚ï¸ Trials podats: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}\")\n",
    "        print(f\"   âŒ Trials fallits: {len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])}\")\n",
    "        \n",
    "        # Avaluar el millor model en test set\n",
    "        if os.path.exists('best_resnet_temp.pth'):\n",
    "            print(f\"\\nğŸ§ª AVALUACIÃ“ EN TEST SET:\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            best_model = ResNetWasteClassifier(\n",
    "                num_classes=len(train_dataset.classes), \n",
    "                dropout=best_trial.params.get('dropout', 0.5)\n",
    "            ).to(device)\n",
    "            best_model.load_state_dict(torch.load('best_resnet_temp.pth'))\n",
    "            \n",
    "            # Crear test loader\n",
    "            test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            \n",
    "            test_metrics = evaluate_model(best_model, test_loader, criterion, device, train_dataset.classes)\n",
    "            \n",
    "            print(f\"ğŸ“Š Test Loss: {test_metrics['test_loss']:.6f}\")\n",
    "            print(f\"ğŸ¯ Test Accuracy: {test_metrics['accuracy']*100:.2f}%\")\n",
    "            \n",
    "            # Generate reports and visualizations\n",
    "            plot_confusion_matrix(test_metrics['true_labels'], test_metrics['predictions'], \n",
    "                                train_dataset.classes, 'confusion_matrix.png')\n",
    "            \n",
    "            # Create a mock study object for reporting if needed\n",
    "            mock_study_data = type('MockStudy', (), {\n",
    "                'trials': study.trials,\n",
    "                'best_trial': best_trial,\n",
    "                'best_value': best_trial.value\n",
    "            })()\n",
    "            \n",
    "            generate_report(mock_study_data, test_metrics, train_dataset.classes, 'optimization_report.json')\n",
    "            plot_optimization_history(mock_study_data, 'optimization_history.png')\n",
    "            \n",
    "            # Save final model with descriptive name\n",
    "            model_filename = f\"best_resnet_model_acc{test_metrics['accuracy']*100:.1f}.pth\"\n",
    "            torch.save(best_model.state_dict(), model_filename)\n",
    "            \n",
    "            # Save complete model configuration\n",
    "            model_config = {\n",
    "                'model_info': {\n",
    "                    'architecture': 'ResNet18',\n",
    "                    'pretrained': True,\n",
    "                    'transfer_learning': True,\n",
    "                    'frozen_layers': ['conv1', 'bn1', 'layer1', 'layer2'],\n",
    "                    'trainable_layers': ['layer3', 'layer4', 'fc']\n",
    "                },\n",
    "                'dataset_info': {\n",
    "                    'num_classes': len(train_dataset.classes),\n",
    "                    'classes': train_dataset.classes,\n",
    "                    'extra_augmentation_classes': list(train_dataset.extra_augmentation_classes),\n",
    "                    'data_split': {'train': 0.6, 'val': 0.2, 'test': 0.2}\n",
    "                },\n",
    "                'best_hyperparameters': best_trial.params,\n",
    "                'performance_metrics': {\n",
    "                    'test_accuracy': test_metrics['accuracy'],\n",
    "                    'test_loss': test_metrics['test_loss'],\n",
    "                    'validation_loss_best': best_trial.value\n",
    "                },\n",
    "                'training_info': {\n",
    "                    'optimizer': 'Adam',\n",
    "                    'loss_function': 'CrossEntropyLoss',\n",
    "                    'scheduler': 'ReduceLROnPlateau',\n",
    "                    'weighted_sampling': True,\n",
    "                    'early_stopping': True\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            with open('resnet_model_config.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(model_config, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            print(\"Files generated:\")\n",
    "            print(f\"   {model_filename} - Optimized ResNet18 model\")\n",
    "            print(\"   resnet_model_config.json - Complete model configuration\")\n",
    "            print(\"   confusion_matrix.png - Confusion matrix\")\n",
    "            print(\"   optimization_report.json - Detailed optimization report\")\n",
    "            print(\"   optimization_history.png - Optimization history\")\n",
    "            print(\"   class_distribution.png - Class distribution\")\n",
    "            \n",
    "            # Performance analysis\n",
    "            print(f\"\\nPERFORMANCE ANALYSIS:\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            class_report = test_metrics['classification_report']\n",
    "            print(f\"{'Class':<10} {'Precision':>10} {'Recall':>10} {'F1-Score':>10} {'Support':>10}\")\n",
    "            print(\"-\" * 60)\n",
    "            for class_name in train_dataset.classes:\n",
    "                if class_name in class_report:\n",
    "                    p = class_report[class_name]['precision']\n",
    "                    r = class_report[class_name]['recall']\n",
    "                    f1 = class_report[class_name]['f1-score']\n",
    "                    support = class_report[class_name]['support']\n",
    "                    \n",
    "                    marker = \" *\" if class_name in train_dataset.extra_augmentation_classes else \"\"\n",
    "                    class_display = class_name + marker\n",
    "                    print(f\"{class_display:<10} {p:>10.3f} {r:>10.3f} {f1:>10.3f} {support:>10.0f}\")\n",
    "            \n",
    "            # Global metrics\n",
    "            if 'macro avg' in class_report:\n",
    "                macro = class_report['macro avg']\n",
    "                print(\"-\" * 60)\n",
    "                print(f\"{'Macro Avg':<10} {macro['precision']:>10.3f} {macro['recall']:>10.3f} {macro['f1-score']:>10.3f}\")\n",
    "            \n",
    "            if 'weighted avg' in class_report:\n",
    "                weighted = class_report['weighted avg']\n",
    "                print(f\"{'Weighted Avg':<10} {weighted['precision']:>10.3f} {weighted['recall']:>10.3f} {weighted['f1-score']:>10.3f}\")\n",
    "            \n",
    "            # Identify best and worst performing classes\n",
    "            class_f1_scores = {}\n",
    "            for class_name in train_dataset.classes:\n",
    "                if class_name in class_report:\n",
    "                    class_f1_scores[class_name] = class_report[class_name]['f1-score']\n",
    "            \n",
    "            if class_f1_scores:\n",
    "                best_class = max(class_f1_scores.keys(), key=lambda x: class_f1_scores[x])\n",
    "                worst_class = min(class_f1_scores.keys(), key=lambda x: class_f1_scores[x])\n",
    "                \n",
    "                print(f\"\\nBest performing class: {best_class} (F1: {class_f1_scores[best_class]:.3f})\")\n",
    "                print(f\"Needs improvement: {worst_class} (F1: {class_f1_scores[worst_class]:.3f})\")\n",
    "                \n",
    "                # Analyze effect of extra augmentation\n",
    "                extra_classes_performance = {}\n",
    "                normal_classes_performance = {}\n",
    "                \n",
    "                for class_name in train_dataset.classes:\n",
    "                    if class_name in class_report:\n",
    "                        f1_score = class_report[class_name]['f1-score']\n",
    "                        if class_name in train_dataset.extra_augmentation_classes:\n",
    "                            extra_classes_performance[class_name] = f1_score\n",
    "                        else:\n",
    "                            normal_classes_performance[class_name] = f1_score\n",
    "                \n",
    "                if extra_classes_performance and normal_classes_performance:\n",
    "                    avg_extra = np.mean(list(extra_classes_performance.values()))\n",
    "                    avg_normal = np.mean(list(normal_classes_performance.values()))\n",
    "                    \n",
    "                    print(f\"\\nEFFECT OF EXTRA AUGMENTATION:\")\n",
    "                    print(f\"   Classes with extra augmentation (vidre, textil): F1 avg = {avg_extra:.3f}\")\n",
    "                    print(f\"   Normal classes: F1 avg = {avg_normal:.3f}\")\n",
    "                    \n",
    "                    if avg_extra > avg_normal:\n",
    "                        print(f\"   Extra augmentation improved performance (+{avg_extra-avg_normal:.3f})\")\n",
    "                    else:\n",
    "                        print(f\"   Extra augmentation did not significantly improve performance\")\n",
    "            \n",
    "            # Instructions for using the trained model\n",
    "            print(f\"\\nHOW TO USE THE TRAINED MODEL:\")\n",
    "            print(\"-\" * 60)\n",
    "            print(\"```python\")\n",
    "            print(\"import torch\")\n",
    "            print(\"from torchvision import transforms\")\n",
    "            print(\"import json\")\n",
    "            print()\n",
    "            print(\"# Load configuration\")\n",
    "            print(\"with open('resnet_model_config.json', 'r') as f:\")\n",
    "            print(\"    config = json.load(f)\")\n",
    "            print()\n",
    "            print(\"# Create model\")\n",
    "            print(\"model = ResNetWasteClassifier(\")\n",
    "            print(f\"    num_classes={len(train_dataset.classes)},\")\n",
    "            print(f\"    dropout={best_trial.params.get('dropout', 0.5)}\")\n",
    "            print(\")\")\n",
    "            print()\n",
    "            print(\"# Load weights\")\n",
    "            print(f\"model.load_state_dict(torch.load('{model_filename}'))\")\n",
    "            print(\"model.eval()\")\n",
    "            print()\n",
    "            print(\"# Preprocess image\")\n",
    "            print(\"transform = transforms.Compose([\")\n",
    "            print(\"    transforms.Resize((224, 224)),\")\n",
    "            print(\"    transforms.ToTensor(),\")\n",
    "            print(\"    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\")\n",
    "            print(\"])\")\n",
    "            print(\"```\")\n",
    "            \n",
    "            # Clean up temporary file\n",
    "            if os.path.exists('best_resnet_temp.pth'):\n",
    "                os.remove('best_resnet_temp.pth')\n",
    "            \n",
    "            print(f\"\\nPROCESS COMPLETED SUCCESSFULLY!\")\n",
    "            \n",
    "        else:\n",
    "            print(\"Warning: Temporary model file not found\")\n",
    "            \n",
    "    else:\n",
    "        print(\"No successful trials completed\")\n",
    "        print(\"Please verify:\")\n",
    "        print(\"   - Dataset path: 'images_6classes/'\")\n",
    "        print(\"   - Folder structure: images_6classes/[class]/[images]\")\n",
    "        print(\"   - Classes: plastics, metalls, paper, vidre, organic, textil\")\n",
    "        print(\"   - Available GPU memory\")\n",
    "        print(\"   - Image formats (PNG/JPG)\")\n",
    "\n",
    "    # Final system information\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"WASTE CLASSIFICATION SYSTEM INFORMATION\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    print(\"Waste classes (6):\")\n",
    "    for i, class_name in enumerate(['plastics', 'metalls', 'paper', 'vidre', 'organic', 'textil']):\n",
    "        marker = \" *\" if class_name in ['vidre', 'textil'] else \"\"\n",
    "        print(f\"   {i}: {class_name}{marker}\")\n",
    "\n",
    "    print(\"\\nModel architecture:\")\n",
    "    print(\"   Base: ResNet18 (pretrained on ImageNet)\")\n",
    "    print(\"   Frozen: conv1, bn1, layer1, layer2\")\n",
    "    print(\"   Trainable: layer3, layer4, fc\")\n",
    "    print(\"   Output classes: 6\")\n",
    "\n",
    "    print(\"\\nTraining configuration:\")\n",
    "    print(\"   Dataset structure: Flat by classes\")\n",
    "    print(\"   Balancing: WeightedRandomSampler\")\n",
    "    print(\"   Augmentation: Dynamic + extra for vidre/textil\")\n",
    "    print(\"   Split: 60% train / 20% val / 20% test\")\n",
    "    print(\"   Optimization: Optuna TPE + MedianPruner\")\n",
    "    print(\"   Scheduler: ReduceLROnPlateau\")\n",
    "    print(\"   Early Stopping: Patience 5 epochs\")\n",
    "\n",
    "    print(f\"\\nEND OF RESNET18 OPTIMIZATION PROCESS\")\n",
    "    print(\"Model ready to classify 6 types of waste!\")\n",
    "\n",
    "    # Final cleanup\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139510ec-2a04-4148-aa35-747409877f63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
